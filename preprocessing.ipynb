{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c76c31e-d877-489a-9de3-f89398bd869a",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e74c96-fdc7-4b9d-a7f1-c9d7fae1518c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82290bc0-882c-4a20-abdc-a8b5cd299034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 878 ms (started: 2023-03-02 21:43:08 -05:00)\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "import warnings\n",
    "import math\n",
    "import db_func\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_notebook, push_notebook, show\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date, datetime\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "try:\n",
    "    %load_ext autotime\n",
    "    %load_ext jupyterlab_notify\n",
    "except:\n",
    "    !pip3 install ipython-autotime\n",
    "    %load_ext autotime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94fd375-bed8-4199-80a1-02acbe8bc14f",
   "metadata": {},
   "source": [
    "## Get Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5197d66d-5341-4d9a-935d-14ba1514ac8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 281 ms (started: 2023-03-02 21:43:09 -05:00)\n"
     ]
    }
   ],
   "source": [
    "conn = db_func.get_conn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faadde39-4b71-4e8f-b4f9-18ed611d2552",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8b0f83-4850-4a66-b5a6-7f6734f0b546",
   "metadata": {},
   "source": [
    "match_df: The final processed dataset to be used in the machine learning models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a556fbf-de3a-40b3-8049-9c70f146a9f6",
   "metadata": {},
   "source": [
    "## Populate Dataframes From Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3686fb-377d-4b14-8a6f-2d4f0dcaa7c1",
   "metadata": {},
   "source": [
    "### SQL Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff3e227d-5b62-49b2-82fc-6eb644b730e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3min 43s (started: 2023-03-02 21:43:31 -05:00)\n"
     ]
    }
   ],
   "source": [
    "match_query = '''SELECT\n",
    "\t\t\t\tm.match_id,  m.away_id, m.home_id,\n",
    "\t\t\t\tm.date, m.away_pts, m.home_pts, m.playoff_game,\n",
    "\t\t\t\th_ml.home_ml, a_ml.away_ml,\n",
    "\t\t\t\th_ps.home_spread, a_ps.away_spread,\n",
    "\t\t\t\th_ps.home_ps_odds, a_ps.away_ps_odds,\n",
    "\t\t\t\tover.over, under.under, ou.spread\n",
    "\t\t\tFROM match AS m\n",
    "\t\t\tLEFT OUTER JOIN\n",
    "\t\t\t(\n",
    "\t\t\t\tSELECT\n",
    "\t\t\t\t\tAVG(decimal_odds) AS home_ml,\n",
    "\t\t\t\t\tm.match_id AS match_id\n",
    "\t\t\t\tFROM\n",
    "\t\t\t\t\todds AS o, team AS t1, team as t2,\n",
    "\t\t\t\t\tmatch AS m\n",
    "\t\t\t\tWHERE\n",
    "\t\t\t\t\to.bet_type_id = 1 AND\n",
    "\t\t\t\t\to.match_id = m.match_id AND\n",
    "\t\t\t\t\to.team_id = m.home_id\n",
    "\t\t\t\tGROUP BY m.match_id\n",
    "\t\t\t) AS h_ml ON m.match_id = h_ml.match_id\n",
    "\t\t\tLEFT OUTER JOIN\n",
    "\t\t\t(\n",
    "\t\t\t\tSELECT\n",
    "\t\t\t\t\tAVG(decimal_odds) AS away_ml,\n",
    "\t\t\t\t\tm.match_id AS match_id\n",
    "\t\t\t\tFROM\n",
    "\t\t\t\t\todds AS o, team AS t1, team as t2,\n",
    "\t\t\t\t\tmatch AS m\n",
    "\t\t\t\tWHERE\n",
    "\t\t\t\t\to.bet_type_id = 1 AND\n",
    "\t\t\t\t\to.match_id = m.match_id AND\n",
    "\t\t\t\t\to.team_id = m.away_id\n",
    "\t\t\t\tGROUP BY m.match_id\n",
    "\t\t\t) AS a_ml ON m.match_id = a_ml.match_id\n",
    "\t\t\tLEFT OUTER JOIN\n",
    "\t\t\t(\n",
    "\t\t\t\tSELECT\n",
    "\t\t\t\t\tAVG(decimal_odds) AS home_ps_odds,\n",
    "\t\t\t\t\tAVG(spread) AS home_spread,\n",
    "\t\t\t\t\tm.match_id AS match_id\n",
    "\t\t\t\tFROM\n",
    "\t\t\t\t\todds AS o, team AS t1, team as t2,\n",
    "\t\t\t\t\tmatch AS m\n",
    "\t\t\t\tWHERE\n",
    "\t\t\t\t\to.bet_type_id = 2 AND\n",
    "\t\t\t\t\to.match_id = m.match_id AND\n",
    "\t\t\t\t\to.team_id = m.home_id\n",
    "\t\t\t\tGROUP BY m.match_id\n",
    "\t\t\t) AS h_ps ON m.match_id = h_ps.match_id\n",
    "\t\t\tLEFT OUTER JOIN\n",
    "\t\t\t(\n",
    "\t\t\t\tSELECT\n",
    "\t\t\t\t\tAVG(decimal_odds) AS away_ps_odds,\n",
    "\t\t\t\t\tAVG(spread) AS away_spread,\n",
    "\t\t\t\t\tm.match_id AS match_id\n",
    "\t\t\t\tFROM\n",
    "\t\t\t\t\todds AS o, team AS t1, team as t2,\n",
    "\t\t\t\t\tmatch AS m\n",
    "\t\t\t\tWHERE\n",
    "\t\t\t\t\to.bet_type_id = 2 AND\n",
    "\t\t\t\t\to.match_id = m.match_id AND\n",
    "\t\t\t\t\to.team_id = m.away_id\n",
    "\t\t\t\tGROUP BY m.match_id\n",
    "\t\t\t) AS a_ps ON m.match_id = a_ps.match_id\n",
    "\t\t\tLEFT OUTER JOIN\n",
    "\t\t\t(\n",
    "\t\t\t\tSELECT\n",
    "\t\t\t\t\tAVG(decimal_odds) AS under,\n",
    "\t\t\t\t\tm.match_id AS match_id\n",
    "\t\t\t\tFROM\n",
    "\t\t\t\t\todds AS o, match AS m\n",
    "\t\t\t\tWHERE\n",
    "\t\t\t\t\to.bet_type_id = 3 AND\n",
    "\t\t\t\t\to.over_under = 'under' AND\n",
    "\t\t\t\t\to.match_id = m.match_id\n",
    "\t\t\t\tGROUP BY m.match_id\n",
    "\t\t\t) AS under ON m.match_id = under.match_id\n",
    "\t\t\tLEFT OUTER JOIN\n",
    "\t\t\t(\n",
    "\t\t\t\tSELECT\n",
    "\t\t\t\t\tAVG(decimal_odds) AS over,\n",
    "\t\t\t\t\tm.match_id AS match_id\n",
    "\t\t\t\tFROM\n",
    "\t\t\t\t\todds AS o, match AS m\n",
    "\t\t\t\tWHERE\n",
    "\t\t\t\t\to.bet_type_id = 3 AND\n",
    "\t\t\t\t\to.over_under = 'over' AND\n",
    "\t\t\t\t\to.match_id = m.match_id\n",
    "\t\t\t\tGROUP BY m.match_id\n",
    "\t\t\t) AS over ON m.match_id = over.match_id\n",
    "\t\t\tLEFT OUTER JOIN\n",
    "\t\t\t(\n",
    "\t\t\t\tSELECT\n",
    "\t\t\t\t\tAVG(spread) AS spread,\n",
    "\t\t\t\t\tm.match_id AS match_id\n",
    "\t\t\t\tFROM\n",
    "\t\t\t\t\todds AS o, match AS m\n",
    "\t\t\t\tWHERE\n",
    "\t\t\t\t\to.bet_type_id = 3 AND\n",
    "\t\t\t\t\to.match_id = m.match_id\n",
    "\t\t\t\tGROUP BY m.match_id\n",
    "\t\t\t) AS ou ON m.match_id = ou.match_id\n",
    "\t\t\tWHERE date >= DATE('2021-10-29')\n",
    "\t\t\tORDER BY date ASC\n",
    "\t\t\t'''\n",
    "\n",
    "season_query = '''SELECT *\n",
    "\t\t\t\tFROM season'''\n",
    "\n",
    "player_performance_query = '''SELECT p.*, m.date\n",
    "\t\t\t\t\t\t\tFROM player_performance as p, match as m\n",
    "\t\t\t\t\t\t\tWHERE m.match_id = p.match_id\n",
    "\t\t\t\t\t\t\tAND m.date >= DATE('2021-10-29')\n",
    "\t\t\t\t\t\t\tORDER BY date ASC'''\n",
    "team_query = '''SELECT * \n",
    "\t\t\t\tFROM team_name'''\n",
    "\n",
    "injury_query = '''SELECT i.* \n",
    "\t\t\t\tFROM injury as i, match as m\n",
    "\t\t\t\tWHERE m.match_id = i.match_id\n",
    "\t\t\t\tAND m.date >= DATE('2021-10-29')\n",
    "\t\t\t\tORDER BY m.date ASC'''\n",
    "\n",
    "match_df = pd.read_sql(match_query, conn)\n",
    "#match_df.set_index('match_id', inplace=True)\n",
    "season_df = pd.read_sql(season_query, conn)\n",
    "pp_df = pd.read_sql(player_performance_query, conn)\n",
    "team_df = pd.read_sql(team_query, conn)\n",
    "injury_df = pd.read_sql(injury_query, conn)\n",
    "match_df['date'] = match_df['date'].map(lambda x: datetime(x.year, x.month, x.day))\n",
    "pp_df['date'] = pp_df['date'].map(lambda x: datetime(x.year, x.month, x.day))\n",
    "season_df['start_date'] =season_df['start_date'].map(lambda x: datetime(x.year, x.month, x.day))\n",
    "season_df['end_date'] = season_df['end_date'].map(lambda x: datetime(x.year, x.month, x.day))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a496fa47-19bc-4690-af41-170180610824",
   "metadata": {},
   "source": [
    "Set the season for each match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8779a12b-da00-476c-87d3-75723c4cace8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 197 Âµs (started: 2023-03-02 21:47:14 -05:00)\n"
     ]
    }
   ],
   "source": [
    "def get_season(date):\n",
    "    return season_df[(season_df['start_date'] <= date) &\n",
    "                     (season_df['end_date'] >= date)]['season'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f74718c6-ec29-47e5-a152-9b96fa8384a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.2 s (started: 2023-03-02 21:47:14 -05:00)\n"
     ]
    }
   ],
   "source": [
    "match_df['season'] = match_df['date'].map(get_season)\n",
    "pp_df['season'] = pp_df['date'].map(get_season)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c469cd8d-d86b-47b5-99ef-bba7e9e298f1",
   "metadata": {},
   "source": [
    "Only matches from seasons 2008-2021 will be used "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b3cfbc-f918-4c54-bc52-d85d708cef66",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae7d644-e0fd-46a5-9194-69bfae70bf25",
   "metadata": {},
   "source": [
    "## Margin of Victory/Loss (MOVL) with respect to the home team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44c5572-f296-48ce-9896-99c0f5c83e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df['home_is_favorite'] = match_df.apply(lambda x: 1 if x['home_ml'] < x['away_ml'] else 0, axis=1)\n",
    "match_df['movl'] = match_df['home_pts'] - match_df['away_pts']\n",
    "match_df['h_win'] = match_df['movl'].map(lambda x: 0 if x < 0 else 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6a377f-cc59-4c3d-a024-815d488b1b00",
   "metadata": {},
   "source": [
    "## Team Elo Rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfe131d-76cd-44c6-87dd-a944881d3cc2",
   "metadata": {},
   "source": [
    "Each team starts at 1500 elo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1295729-41fc-44b3-acf7-a99664f43284",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df['home_elo'] = 1500.0\n",
    "match_df['away_elo'] = 1500.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9600e5-378b-40bd-9713-47b7d127b69e",
   "metadata": {},
   "source": [
    "### Get the previous match of each team to aid elo calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6823a608-5cc9-46e6-b0a5-f81a14a8b6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prev_match(date, team_id, match_df):\n",
    "    return match_df[(match_df[\"date\"] < date) &\n",
    "                    ((match_df[\"home_id\"] == team_id) |\n",
    "                     (match_df[\"away_id\"] == team_id))].tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd6233f-770a-412d-9084-debc9f991d15",
   "metadata": {},
   "source": [
    "### Team elo calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f683830a-b4d4-4199-8445-174b123176c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prev_elo(team_id, season, prev_match):\n",
    "\n",
    "    if prev_match.empty:\n",
    "        prev_elo = 1500.0\n",
    "    elif team_id == prev_match['home_id'].values[0]:\n",
    "        prev_elo = prev_match['home_elo'].values[0]\n",
    "    elif team_id == prev_match['away_id'].values[0]:\n",
    "        prev_elo = prev_match['away_elo'].values[0]\n",
    "    else: \n",
    "        print('err')\n",
    "\n",
    "    if (not prev_match.empty and\n",
    "            (prev_match['season'].values[0]\n",
    "             != season)):\n",
    "        prev_elo = prev_elo * 0.75 + 1505 * 0.25\n",
    "    return prev_elo\n",
    "\n",
    "\n",
    "def update_elo(home_elo, away_elo, movl):\n",
    "    elo_diff = home_elo + 100.0 - away_elo\n",
    "    if movl > 0:\n",
    "        h_s = 1.0\n",
    "        a_s = 0.0\n",
    "        multiplier = ((movl+3)**(0.8))/(7.5+0.006*elo_diff)\n",
    "\n",
    "    else:\n",
    "        h_s = 0.0\n",
    "        a_s = 1.0\n",
    "        multiplier = ((-movl+3)**(0.8))/(7.5+0.006*(-elo_diff))\n",
    "        \n",
    "    exp_h_s = 1.0 / (1.0 + 10.0 ** (-elo_diff/400.0))\n",
    "    exp_a_s = 1.0 - exp_h_s\n",
    "    \n",
    "    k = 20.0 * multiplier\n",
    "\n",
    "    new_home_elo = home_elo + k * (h_s - exp_h_s)\n",
    "    new_away_elo = away_elo + k * (a_s - exp_a_s)\n",
    "\n",
    "    return (new_home_elo, new_away_elo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a46ea97-aaac-4aeb-a87b-fdec9f1d5a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = defaultdict(list)\n",
    "for idx, row in tqdm(match_df.iterrows(), total=match_df.shape[0]):\n",
    "    prev_h_match = get_prev_match(row['date'], row['home_id'], match_df)\n",
    "    prev_a_match = get_prev_match(row['date'], row['away_id'], match_df)\n",
    "    \n",
    "    prev_h_elo = get_prev_elo(\n",
    "        row['home_id'], row['season'], prev_h_match)\n",
    "    prev_a_elo = get_prev_elo(\n",
    "        row['away_id'], row['season'], prev_a_match)    \n",
    "    \n",
    "    new_elos = update_elo(prev_h_elo, prev_a_elo, row['movl'])\n",
    "    d['home_elo'].append(new_elos[0])\n",
    "    d['away_elo'].append(new_elos[1])\n",
    "    \n",
    "    d['prev_home_elo'].append(prev_h_elo)\n",
    "    d['prev_away_elo'].append(prev_a_elo)\n",
    "\n",
    "df = pd.Dataframe(d)\n",
    "match_df.concat([match_df.reset_index(drop=True),\n",
    "\t\t\t\tdf.reset_index(drop=True)],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6765bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in tqdm(match_df.iterrows(), total=match_df.shape[0]):\n",
    "    prev_h_match = get_prev_match(row['date'], row['home_id'], match_df)\n",
    "    prev_a_match = get_prev_match(row['date'], row['away_id'], match_df)\n",
    "\n",
    "    prev_h_elo = get_prev_elo(\n",
    "        row['home_id'], row['season'], prev_h_match)\n",
    "    prev_a_elo = get_prev_elo(\n",
    "        row['away_id'], row['season'], prev_a_match)    \n",
    "\n",
    "    new_elos = update_elo(prev_h_elo, prev_a_elo, row['movl'])\n",
    "    match_df.at[idx, 'home_elo'] = new_elos[0]\n",
    "    match_df.at[idx, 'away_elo'] = new_elos[1]\n",
    "\n",
    "    match_df.at[idx, 'prev_home_elo'] = prev_h_elo\n",
    "    match_df.at[idx, 'prev_away_elo'] = prev_a_elo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b46ec87-56f9-4a46-8979-35ad207e156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import output_file, show\n",
    "def plot_elo(team_id):\n",
    "    #output_notebook()\n",
    "    plot = figure(title=\"Historical Elo Rating\", x_axis_label=\"Date\", y_axis_label=\"Elo\", \n",
    "                  x_axis_type = 'datetime', plot_width=800, plot_height=500)\n",
    "\n",
    "    y = match_df[(match_df['away_id'] == team_id) | (match_df['home_id'] == team_id)]\n",
    "    x = y['date']\n",
    "    y = y.apply(lambda x: x['home_elo'] if x['home_id'] == team_id else x['away_elo'], axis=1)\n",
    "    \n",
    "    team_name = team_df[team_df['team_id'] == team_id]['team_name'].head(1).values[0]\n",
    "    plot.circle(x, y, legend_label = team_name, line_color = 'blue', line_width = 1)\n",
    "    #show(plot)\n",
    "    output_file('elo.html')\n",
    "    show(plot)\n",
    "    # handle = show(plot, notebook_handle=True)\n",
    "\n",
    "    # # Update the plot title in the earlier cell\n",
    "    # push_notebook(handle=handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e7e07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e686b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.resources import INLINE\n",
    "import bokeh.io\n",
    "\n",
    "bokeh.io.output_notebook(INLINE)\n",
    "plot_elo(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fa3417-3fd9-460a-87b4-045e0e21f4df",
   "metadata": {},
   "source": [
    "## Player elo rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddd3b3f-c1dc-4026-85db-6e43346889c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prev_player_match(date, player_id, pp_df):\n",
    "    return pp_df[(pp_df['date'] < date) & \n",
    "                (pp_df['player_id'] == player_id)].tail(1)\n",
    "def get_active_players(match_id, team_id, pp_df):\n",
    "    return  pp_df[(pp_df['match_id'] == match_id) &\n",
    "                      (pp_df['team_id'] == team_id) &\n",
    "                  (pp_df['sp']>0)]\n",
    "\n",
    "def get_complete_roster(match_id, team_id, match_df):\n",
    "    return  pp_df[(pp_df['match_id'] == match_id) &\n",
    "                      (pp_df['team_id'] == team_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72052ef-a9c2-4b8f-a56c-c6352185c7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_df['post_elo'] = 1500\n",
    "pp_df['prev_elo'] = 1500\n",
    "for idx, row in tqdm(match_df.iterrows(), total=match_df.shape[0]):\n",
    "    ## update prev_elo for all players\n",
    "    all_home_players = get_complete_roster(row['match_id'], \n",
    "                                       row['home_id'], pp_df)\n",
    "    all_away_players = get_complete_roster(row['match_id'], \n",
    "                                       row['away_id'], pp_df)\n",
    "\n",
    "    for p_idx, player in pd.concat([all_home_players, all_away_players]).iterrows():\n",
    "        prev_player_match = get_prev_player_match(player['date'], player['player_id'], pp_df)\n",
    "        if prev_player_match.empty:\n",
    "            prev_elo = 1500\n",
    "\n",
    "        else:\n",
    "            prev_elo = prev_player_match['post_elo']\n",
    "            #print(prev_player_match['season'].values[0],player['season'])\n",
    "            if (prev_player_match['season'].values[0] != player['season']):\n",
    "                #tmp = prev_elo\n",
    "                prev_elo = prev_elo * 0.75 + 1505 * 0.25\n",
    "                #print(tmp, prev_elo)\n",
    "        pp_df.at[p_idx, 'prev_elo'] = prev_elo\n",
    "        pp_df.at[p_idx, 'post_elo'] = prev_elo\n",
    "\n",
    "    ## Update post_elo of players that played in current match\n",
    "    home_players = get_active_players(row['match_id'], row['home_id'], pp_df)\n",
    "    away_players = get_active_players(row['match_id'], row['away_id'], pp_df)\n",
    "\n",
    "    injured_players = injury_df[row['match_id'] == injury_df['match_id']]    \n",
    "    if not injured_players.empty:\n",
    "        home_players = home_players[~home_players['player_id'].isin(injured_players['player_id'])]\n",
    "        away_players = away_players[~away_players['player_id'].isin(injured_players['player_id'])]\n",
    "    \n",
    "    home_players_elo_sum = home_players['prev_elo'].sum()\n",
    "    away_players_elo_sum = away_players['prev_elo'].sum()\n",
    "    len_home_players = len(home_players)\n",
    "    len_away_players = len(away_players)\n",
    "\n",
    "    for p_idx, player in home_players.iterrows():\n",
    "        opp_elo = away_players_elo_sum / len_away_players\n",
    "#         opp_elo = away_players_elo_sum * 2 / len_away_players \\\n",
    "#             - (home_players_elo_sum - player['prev_elo']) / (len_home_players-1)\n",
    "        new_elos = update_elo(player['prev_elo'], opp_elo, row['movl'])\n",
    "        pp_df.at[p_idx, 'post_elo'] = new_elos[0]\n",
    "    \n",
    "    for p_idx, player in away_players.iterrows():\n",
    "        opp_elo = home_players_elo_sum / len_home_players\n",
    "#         opp_elo = home_players_elo_sum * 2 / len_home_players \\\n",
    "#             - (away_players_elo_sum - player['prev_elo']) / (len_away_players-1)\n",
    "        new_elos = update_elo(opp_elo, player['prev_elo'], row['movl'])\n",
    "        pp_df.at[p_idx, 'post_elo'] = new_elos[1]\n",
    "\n",
    "    active_home_players = get_active_players(row['match_id'], row['home_id'], pp_df)\n",
    "    active_away_players = get_active_players(row['match_id'], row['away_id'], pp_df)\n",
    "\n",
    "\n",
    "    d['prev_home_player_elo_avg'] = active_home_players['prev_elo'].sum()/len(active_home_players)\n",
    "    d['prev_away_player_elo_avg'] = active_away_players['prev_elo'].sum()/len(active_away_players)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f491d5-d9d1-48e1-99c8-73ff47fc1c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.resources import INLINE\n",
    "import bokeh.io\n",
    "bokeh.io.output_notebook(INLINE)\n",
    "\n",
    "def plot_player_elo(player_id):\n",
    "    output_notebook()\n",
    "    plot = figure(title=\"Historical Elo Rating\", \n",
    "                  x_axis_label=\"Date\", \n",
    "                  y_axis_label=\"Elo\", \n",
    "                  x_axis_type = 'datetime',\n",
    "                  sizing_mode=\"stretch_width\",)\n",
    "\n",
    "    y = pp_df[pp_df['player_id'] == player_id]\n",
    "    x = y['date']\n",
    "    y = y['post_elo']\n",
    "    \n",
    "    team_name = str(player_id)\n",
    "    plot.circle(x, y, legend_label = team_name, line_color = 'blue', line_width = 1)\n",
    "\n",
    "    handle = show(plot, notebook_handle=True)\n",
    "\n",
    "    # Update the plot title in the earlier cell\n",
    "    push_notebook(handle=handle)\n",
    "\n",
    "last_elo = pp_df.sort_values('date').groupby('player_id').tail(1)\n",
    "last_elo = last_elo.sort_values('post_elo', ascending=False)\n",
    "last_elo[last_elo['date']>datetime(2021,1,1)]['post_elo'].mean()\n",
    "lebron = pp_df[(pp_df['player_id'] == 712)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872f5495-4733-4496-82cb-506780d0f16d",
   "metadata": {},
   "source": [
    "## Player Efficiency Rating (PER) Sum of Last 5 Games"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4f7ae8-4182-4b71-a32c-366bd61ce2e3",
   "metadata": {},
   "source": [
    "The Hollinger Player Efficiency Rating for a player is defined as the sum of\n",
    "the following stats\n",
    "\n",
    "\n",
    "| Stat | Weight |\n",
    "| --- | ----------- |\n",
    "| FGM | 85.910 |\n",
    "| Steals | 53.897 |\n",
    "| 3PTM | 51.757 |\n",
    "| FTM | 46.845 |\n",
    "| Blocks | 39.190 |\n",
    "| Offensive Rebounds | 39.190|\n",
    "| Assists | 34.677 |\n",
    "| Defensive Rebounds | 14.707 |\n",
    "| Foul | -17.174 |\n",
    "| FT Miss | -20.091 |\n",
    "| FG Miss | -39.190 |\n",
    "| Turnover | -53.897 |\n",
    "\n",
    " divided by (minutes played)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f929b0-c1e0-4b4b-be33-8fc036d29893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def player_match_eff_rating(player):\n",
    "    per = 0\n",
    "    if player['sp'] > 0:\n",
    "        per = player['fg'] * 85.910 \n",
    "        + player['stl'] * 53.897\n",
    "        + player['threep'] * 51.757\n",
    "        + player['ft'] * 46.845\n",
    "        + player['blk'] * 39.190 \n",
    "        + player['orb'] * 39.190\n",
    "        + player['drb'] * 34.677\n",
    "        + player['ast'] * 14.707\n",
    "        - player['pf'] * 17.174 \n",
    "        - (player['fta'] - player['ft']) * 20.091 \n",
    "        - (player['fga'] - player['fg']) * 39.190\n",
    "        - player['tov'] * 53.897 \n",
    "        \n",
    "        per = per / (player['sp']/60.0)\n",
    "    return per\n",
    "\n",
    "def team_match_eff_rating(team_id, match_id, pp_df):\n",
    "    df = pp_df[(pp_df['team_id'] == team_id) &\n",
    "                        (pp_df['match_id'] == match_id)]\n",
    "    return df['per'].sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6534562f-3125-42cf-8c0d-061c247441df",
   "metadata": {},
   "outputs": [],
   "source": [
    "### To get head on head matches for an opponent, set opponent_id\n",
    "def get_prev_matches(date, team_id, match_df, opponent_id = 0):\n",
    "    if opponent_id:\n",
    "        return match_df[(match_df[\"date\"] < date) &\n",
    "                        (((match_df[\"home_id\"] == team_id) & \n",
    "                          (match_df[\"away_id\"] == opponent_id)) |\n",
    "                         ((match_df[\"home_id\"] == opponent_id) & \n",
    "                          (match_df[\"away_id\"] == team_id)))]\n",
    "    else:\n",
    "        return match_df[(match_df[\"date\"] < date) &\n",
    "                    ((match_df[\"home_id\"] == team_id) |\n",
    "                     (match_df[\"away_id\"] == team_id))]\n",
    "\n",
    "def get_past_per_sum(team_id, prev_matches, i):\n",
    "    if len(prev_matches) < i: \n",
    "        return None\n",
    "    prev_matches['res'] =  prev_matches.apply(lambda x:\n",
    "                             x['home_per'] if x['home_id'] == team_id\n",
    "                             else x['away_per'], axis=1)\n",
    "    return prev_matches['res'].sum()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29776c62-326e-48d9-92d1-83a0758808c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_df['per'] = pp_df.apply(player_match_eff_rating, axis=1)\n",
    "\n",
    "match_df['away_per'] = match_df.apply(lambda x: team_match_eff_rating(\n",
    "\tx['away_id'],x['match_id'], pp_df), axis=1)\n",
    "match_df['home_per'] = match_df.apply(lambda x: team_match_eff_rating(\n",
    "\tx['home_id'],x['match_id'], pp_df), axis=1)\n",
    "\n",
    "match_df['prev_3_home_per'] = match_df.apply(lambda x: \n",
    "\t\t\t\t\t\t\t\tget_past_per_sum(x['home_id'], \n",
    "\t\t\t\t\t\t\t\t\tget_prev_matches(x['date'], \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tx['home_id'],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tmatch_df).tail(3),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t3), axis=1)\n",
    "match_df['prev_3_away_per'] = match_df.apply(lambda x: \n",
    "\t\t\t\t\t\t\t\tget_past_per_sum(x['away_id'], \n",
    "\t\t\t\t\t\t\t\t\tget_prev_matches(x['date'], \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tx['away_id'],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tmatch_df).tail(3),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t3), axis=1)\n",
    "\n",
    "match_df['prev_hth_home_per'] = match_df.apply(lambda x: \n",
    "\t\t\t\t\t\t\t\tget_past_per_sum(x['home_id'], \n",
    "\t\t\t\t\t\t\t\t\tget_prev_matches(x['date'], \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tx['home_id'],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tmatch_df,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tx['away_id']\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t).tail(1),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t1), axis=1)\n",
    "match_df['prev_hth_away_per'] = match_df.apply(lambda x: \n",
    "\t\t\t\t\t\t\t\tget_past_per_sum(x['away_id'], \n",
    "\t\t\t\t\t\t\t\t\tget_prev_matches(x['date'], \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tx['away_id'],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tmatch_df,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tx['home_id']\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t).tail(1),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t1), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fc2638-a1dc-4511-8fae-d1d3b618e422",
   "metadata": {},
   "source": [
    "## FG%, 3P%, FT%, ORB, DRB, TRB, TOV, AST, STL, BLK, DRTG, ORTG, EFG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfb16cb-d9ab-4c0e-ac3f-f9185e17bea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "d = defaultdict(list)\n",
    "for idx, row in tqdm(match_df.iterrows(), total=match_df.shape[0]):\n",
    "    home_players = get_active_players(row['match_id'], row['home_id'], pp_df)\n",
    "    away_players = get_active_players(row['match_id'], row['away_id'], pp_df)\n",
    "    d['home_bpm'].append(home_players['bpm'].sum())\n",
    "    d['away_bpm'].append(away_players['bpm'].sum())\n",
    "    \n",
    "    d['home_fg'].append(home_players['fg'].sum())\n",
    "    d['away_fg'].append(away_players['fg'].sum())\n",
    "    d['home_fg_pct'].append(home_players['fg_pct'].mean())\n",
    "    d['away_fg_pct'].append(away_players['fg_pct'].mean())\n",
    "    \n",
    "    d['home_3p'].append(home_players['threep'].sum())\n",
    "    d['away_3p'].append(away_players['threep'].sum())\n",
    "    d['home_3pa'].append(home_players['threepa'].sum())\n",
    "    d['away_3pa'].append(away_players['threepa'].sum())\n",
    "    d['home_3p_pct'].append(home_players['threep_pct'].mean())\n",
    "    d['away_3p_pct'].append(away_players['threep_pct'].mean())\n",
    "    \n",
    "    d['home_ft'].append(home_players['ft'].sum())\n",
    "    d['away_ft'].append(away_players['ft'].sum())\n",
    "    d['home_ft_pct'].append(home_players['ft_pct'].mean())\n",
    "    d['away_ft_pct'].append(away_players['ft_pct'].mean())\n",
    "    \n",
    "    d['home_orb'].append(home_players['orb'].sum())\n",
    "    d['away_orb'].append(away_players['orb'].sum())\n",
    "    d['home_orb_pct'].append(home_players['orb_pct'].mean())\n",
    "    d['away_orb_pct'].append(away_players['orb_pct'].mean())\n",
    "    \n",
    "    d['home_drb'].append(home_players['drb'].sum())\n",
    "    d['away_drb'].append(away_players['drb'].sum())\n",
    "    d['home_drb_pct'].append(home_players['drb_pct'].mean())\n",
    "    d['away_drb_pct'].append(away_players['drb_pct'].mean())\n",
    "    \n",
    "    d['home_trb'].append(home_players['trb'].sum())\n",
    "    d['away_trb'].append(away_players['trb'].sum())\n",
    "    d['home_trb_pct'].append(home_players['trb_pct'].mean())\n",
    "    d['away_trb_pct'].append(away_players['trb_pct'].mean())\n",
    "    \n",
    "    d['home_tov'].append(home_players['tov'].sum())\n",
    "    d['away_tov'].append(away_players['tov'].sum())\n",
    "    d['home_tov_pct'].append(home_players['tov_pct'].mean())\n",
    "    d['away_tov_pct'].append(away_players['tov_pct'].mean())\n",
    "    \n",
    "    d['home_ast'].append(home_players['ast'].sum())\n",
    "    d['away_ast'].append(away_players['ast'].sum())\n",
    "    d['home_ast_pct'].append(home_players['ast_pct'].mean())\n",
    "    d['away_ast_pct'].append(away_players['ast_pct'].mean())\n",
    "    \n",
    "    d['home_stl'].append(home_players['stl'].sum())\n",
    "    d['away_stl'].append(away_players['stl'].sum())\n",
    "    d['home_stl_pct'].append(home_players['stl_pct'].mean())\n",
    "    d['away_stl_pct'].append(away_players['stl_pct'].mean())\n",
    "    \n",
    "    d['home_blk'].append(home_players['blk'].sum())\n",
    "    d['away_blk'].append(away_players['blk'].sum())\n",
    "    d['home_blk_pct'].append(home_players['blk_pct'].mean())\n",
    "    d['away_blk_pct'].append(away_players['blk_pct'].mean())\n",
    "    \n",
    "    d['home_drtg'].append(home_players['drtg'].mean())\n",
    "    d['away_drtg'].append(away_players['drtg'].mean())\n",
    "    \n",
    "    d['home_ortg'].append(home_players['ortg'].mean())\n",
    "    d['away_ortg'].append(away_players['ortg'].mean())\n",
    "    \n",
    "    d['home_efg_pct'].append(home_players['efg_pct'].mean())\n",
    "    d['away_efg_pct'].append(away_players['efg_pct'].mean())\n",
    "    \n",
    "    d['sp'].append(home_players['sp'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b70854-8ae8-45ae-9187-7c8bc2ca625f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(d)\n",
    "match_df = pd.concat([match_df.reset_index(drop=True),\n",
    "                      df.reset_index(drop=True)],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eb68eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3pa():\n",
    "    #output_notebook()\n",
    "    plot = figure(title=\"3 Pointers Attempted\", x_axis_label=\"Date\", y_axis_label=\"3pa\", \n",
    "                  x_axis_type = 'datetime', plot_width=800, plot_height=500)\n",
    "    y = match_df[400:]\n",
    "    x = match_df[400:]['date']\n",
    "    y = y.apply(lambda x: ((x['home_3pa'] + x['away_3pa']))/(x['sp1']/(60*10)), axis=1)\n",
    "    print(y)\n",
    "    plot.circle(x, y, line_color = 'blue', line_width = 1)\n",
    "    output_file('3pa.html')\n",
    "    show(plot)\n",
    "plot_3pa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14967dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(match_df['home_bpm'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1250271-c733-4481-bcce-4fc98fcec622",
   "metadata": {},
   "source": [
    "## Calculating SMA and EMA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2156b2-692b-47ea-9b4e-c7fe5e538613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ema(current, prev_ema, window_size, smoothing=2.0):\n",
    "    k = smoothing / (1 + window_size)\n",
    "    return current * k + prev_ema * (1-k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8023d251-5896-4093-ac98-0c69209c70df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prev_team_sum(team_id, home_col, prev_matches):\n",
    "    away_col = home_col.replace('home', 'away')\n",
    "    prev_matches['res'] =  prev_matches.apply(lambda x:\n",
    "                             x[home_col] if x['home_id'] == team_id\n",
    "                             else x[away_col], axis=1)\n",
    "    return prev_matches['res'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3d78f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothing = 2\n",
    "\n",
    "window_sizes = [3]\n",
    "hth_window_sizes = [2]\n",
    "\n",
    "for w in tqdm(range(len(hth_window_sizes))):\n",
    "\thth_window_size = hth_window_sizes[w]\n",
    "\tema_h_hth_features = [(f'prev_hth_home_pts_ema{hth_window_size}',       f'post_hth_home_pts_ema{hth_window_size}'),\n",
    "\t\t\t\t\t(f'prev_hth_home_bpm_ema{hth_window_size}',       f'post_hth_home_bpm_ema{hth_window_size}'),\n",
    "\t\t\t\t\t(f'prev_hth_home_fg_ema{hth_window_size}',        f'post_hth_home_fg_ema{hth_window_size}'),\n",
    "\t\t\t\t\t(f'prev_hth_home_fg_pct_ema{hth_window_size}',    f'post_hth_home_fg_pct_ema{hth_window_size}'),\n",
    "\t\t\t\t\t(f'prev_hth_home_3p_ema{hth_window_size}',        f'post_hth_home_3p_ema{hth_window_size}'),\n",
    "\t\t\t\t\t(f'prev_hth_home_3p_pct_ema{hth_window_size}',    f'post_hth_home_3p_pct_ema{hth_window_size}'),\n",
    "\t\t\t\t\t(f'prev_hth_home_ft_ema{hth_window_size}',        f'post_hth_home_ft_ema{hth_window_size}'),\n",
    "\t\t\t\t\t(f'prev_hth_home_ft_pct_ema{hth_window_size}',    f'post_hth_home_ft_pct_ema{hth_window_size}'),\n",
    "\t\t\t\t\t(f'prev_hth_home_orb_ema{hth_window_size}',       f'post_hth_home_orb_ema{hth_window_size}'),\n",
    "\t\t\t\t\t(f'prev_hth_home_orb_pct_ema{hth_window_size}',   f'post_hth_home_orb_pct_ema{hth_window_size}'),\n",
    "\t\t\t\t\t(f'prev_hth_home_drb_ema{hth_window_size}',       f'post_hth_home_drb_ema{hth_window_size}'),\n",
    "\t\t\t\t\t(f'prev_hth_home_drb_pct_ema{hth_window_size}',   f'post_hth_home_drb_pct_ema{hth_window_size}'),\n",
    "\t\t\t\t\t(f'prev_hth_home_trb_ema{hth_window_size}',       f'post_hth_home_trb_ema{hth_window_size}'),\n",
    "\t\t\t\t\t(f'prev_hth_home_trb_pct_ema{hth_window_size}',   f'post_hth_home_trb_pct_ema{hth_window_size}'),\n",
    "\t\t\t\t\t(f'prev_hth_home_tov_ema{hth_window_size}',       f'post_hth_home_tov_ema{hth_window_size}'),\n",
    "\t\t\t\t\t(f'prev_hth_home_tov_pct_ema{hth_window_size}',   f'post_hth_home_tov_pct_ema{hth_window_size}'),\n",
    "\t\t\t\t\t(f'prev_hth_home_ast_ema{hth_window_size}',       f'post_hth_home_ast_ema{hth_window_size}'),\n",
    "\t\t\t\t\t(f'prev_hth_home_ast_pct_ema{hth_window_size}',   f'post_hth_home_ast_pct_ema{hth_window_size}'),\n",
    "\t\t\t\t\t(f'prev_hth_home_stl_ema{hth_window_size}',       f'post_hth_home_stl_ema{hth_window_size}'),\n",
    "\t\t\t\t\t(f'prev_hth_home_stl_pct_ema{hth_window_size}',   f'post_hth_home_stl_pct_ema{hth_window_size}'),\n",
    "\t\t\t\t\t(f'prev_hth_home_blk_ema{hth_window_size}',       f'post_hth_home_blk_ema{hth_window_size}'),\n",
    "\t\t\t\t\t(f'prev_hth_home_blk_pct_ema{hth_window_size}',   f'post_hth_home_blk_pct_ema{hth_window_size}'),\n",
    "\t\t\t\t\t(f'prev_hth_home_drtg_ema{hth_window_size}',      f'post_hth_home_drtg_ema{hth_window_size}'),\n",
    "\t\t\t\t\t(f'prev_hth_home_ortg_ema{hth_window_size}',      f'post_hth_home_ortg_ema{hth_window_size}'),\n",
    "\t\t\t\t\t(f'prev_hth_home_efg_pct_ema{hth_window_size}',   f'post_hth_home_efg_pct_ema{hth_window_size}')]\n",
    "\n",
    "\tema_a_hth_features = [(f[0].replace('home','away'), f[1].replace('home','away')) for f in ema_h_hth_features]\n",
    "\tsma_h_hth_features = [(f[0].replace('ema','sma'), f[1].replace('ema','sma')) for f in ema_h_hth_features]\n",
    "\tsma_a_hth_features = [(f[0].replace('home','away'), f[1].replace('home','away')) for f in sma_h_hth_features]\n",
    "\tfor idx, row in tqdm(match_df.iterrows(), total=match_df.shape[0]):\n",
    "\t\tprev_hth_matches = get_prev_matches(row['date'], row['home_id'], match_df, row['away_id']).tail(hth_window_size)\n",
    "\t\tlen_prev_hth_matches = len(prev_hth_matches)\n",
    "\t\tfor i in range(len(ema_h_hth_features)):\n",
    "\t\t\th_feature = re.findall('home_.*_ema', ema_h_hth_features[i][0])[0].replace('_ema', '')\n",
    "\t\t\ta_feature = h_feature.replace('home', 'away') \n",
    "\t\t\tif not prev_hth_matches.empty:\n",
    "\t\t\t\tprev_match = prev_hth_matches.iloc[-1:]\n",
    "\t\t\t\tmatch_df.at[idx,sma_h_hth_features[i][0]] = get_prev_team_sum(row['home_id'], h_feature, prev_hth_matches)/len_prev_hth_matches    \n",
    "\t\t\t\tmatch_df.at[idx,sma_a_hth_features[i][0]] = get_prev_team_sum(row['away_id'], a_feature, prev_hth_matches)/len_prev_hth_matches    \n",
    "\n",
    "\n",
    "\t\t\t\tif len_prev_hth_matches < hth_window_size:\n",
    "\t\t\t\t\tmatch_df.at[idx,ema_h_hth_features[i][0]] = match_df.loc[idx,sma_h_hth_features[i][0]] \n",
    "\t\t\t\t\tmatch_df.at[idx,ema_h_hth_features[i][1]] = (match_df.loc[idx,sma_h_hth_features[i][0]] \\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t* len_prev_hth_matches + row[h_feature])/(len_prev_hth_matches + 1)\n",
    "\t\t\t\t\tmatch_df.at[idx,ema_a_hth_features[i][0]] = match_df.loc[idx,sma_a_hth_features[i][0]] \n",
    "\t\t\t\t\tmatch_df.at[idx,ema_a_hth_features[i][1]] = (match_df.loc[idx,sma_a_hth_features[i][0]] \\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t* len_prev_hth_matches + row[a_feature])/(len_prev_hth_matches + 1)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tmatch_df.at[idx,ema_h_hth_features[i][0]] = prev_match[ema_h_hth_features[i][1]] \\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tif prev_match['home_id'].values[0] == row['home_id'] \\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\telse prev_match[ema_a_hth_features[i][1]]\n",
    "\n",
    "\t\t\t\t\tmatch_df.at[idx,ema_h_hth_features[i][1]] = ema(row[h_feature],  \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tmatch_df.loc[idx,ema_h_hth_features[i][0]], \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\thth_window_size)\n",
    "\t\t\t\t\tmatch_df.at[idx,ema_a_hth_features[i][0]] = prev_match[ema_h_hth_features[i][1]] \\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tif prev_match['home_id'].values[0] == row['home_id'] \\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\telse prev_match[ema_a_hth_features[i][1]]\n",
    "\n",
    "\t\t\t\t\tmatch_df.at[idx,ema_a_hth_features[i][1]] = ema(row[h_feature],  \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tmatch_df.loc[idx,ema_a_hth_features[i][0]], \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\thth_window_size)\n",
    "\t\t\telse:\n",
    "\t\t\t\tmatch_df.at[idx,ema_h_hth_features[i][1]] = row[h_feature]\n",
    "\t\t\t\tmatch_df.at[idx,ema_a_hth_features[i][1]] = row[a_feature]\n",
    "\n",
    "\n",
    "for w in tqdm(range(len(window_sizes))):\n",
    "\twindow_size = window_sizes[w]\n",
    "\n",
    "\tema_h_features = [(f'prev_home_pts_ema{window_size}',       f'post_home_pts_ema{window_size}'),\n",
    "\t\t\t\t\t(f'prev_home_bpm_ema{window_size}',       f'post_home_bpm_ema{window_size}'),\n",
    "\t\t\t\t\t(f'prev_home_fg_ema{window_size}',        f'post_home_fg_ema{window_size}'),\n",
    "\t\t\t\t\t(f'prev_home_fg_pct_ema{window_size}',    f'post_home_fg_pct_ema{window_size}'),\n",
    "\t\t\t\t\t(f'prev_home_3p_ema{window_size}',        f'post_home_3p_ema{window_size}'),\n",
    "\t\t\t\t\t(f'prev_home_3p_pct_ema{window_size}',    f'post_home_3p_pct_ema{window_size}'),\n",
    "\t\t\t\t\t(f'prev_home_ft_ema{window_size}',        f'post_home_ft_ema{window_size}'),\n",
    "\t\t\t\t\t(f'prev_home_ft_pct_ema{window_size}',    f'post_home_ft_pct_ema{window_size}'),\n",
    "\t\t\t\t\t(f'prev_home_orb_ema{window_size}',       f'post_home_orb_ema{window_size}'),\n",
    "\t\t\t\t\t(f'prev_home_orb_pct_ema{window_size}',   f'post_home_orb_pct_ema{window_size}'),\n",
    "\t\t\t\t\t(f'prev_home_drb_ema{window_size}',       f'post_home_drb_ema{window_size}'),\n",
    "\t\t\t\t\t(f'prev_home_drb_pct_ema{window_size}',   f'post_home_drb_pct_ema{window_size}'),\n",
    "\t\t\t\t\t(f'prev_home_trb_ema{window_size}',       f'post_home_trb_ema{window_size}'),\n",
    "\t\t\t\t\t(f'prev_home_trb_pct_ema{window_size}',   f'post_home_trb_pct_ema{window_size}'),\n",
    "\t\t\t\t\t(f'prev_home_tov_ema{window_size}',       f'post_home_tov_ema{window_size}'),\n",
    "\t\t\t\t\t(f'prev_home_tov_pct_ema{window_size}',   f'post_home_tov_pct_ema{window_size}'),\n",
    "\t\t\t\t\t(f'prev_home_ast_ema{window_size}',       f'post_home_ast_ema{window_size}'),\n",
    "\t\t\t\t\t(f'prev_home_ast_pct_ema{window_size}',   f'post_home_ast_pct_ema{window_size}'),\n",
    "\t\t\t\t\t(f'prev_home_stl_ema{window_size}',       f'post_home_stl_ema{window_size}'),\n",
    "\t\t\t\t\t(f'prev_home_stl_pct_ema{window_size}',   f'post_home_stl_pct_ema{window_size}'),\n",
    "\t\t\t\t\t(f'prev_home_blk_ema{window_size}',       f'post_home_blk_ema{window_size}'),\n",
    "\t\t\t\t\t(f'prev_home_blk_pct_ema{window_size}',   f'post_home_blk_pct_ema{window_size}'),\n",
    "\t\t\t\t\t(f'prev_home_drtg_ema{window_size}',      f'post_home_drtg_ema{window_size}'),\n",
    "\t\t\t\t\t(f'prev_home_ortg_ema{window_size}',      f'post_home_ortg_ema{window_size}'),\n",
    "\t\t\t\t\t(f'prev_home_efg_pct_ema{window_size}',   f'post_home_efg_pct_ema{window_size}')]\n",
    "\n",
    "\tema_a_features = [(f[0].replace('home','away'), f[1].replace('home','away')) for f in ema_h_features]\n",
    "\tsma_h_features = [(f[0].replace('ema','sma'), f[1].replace('ema','sma')) for f in ema_h_features]\n",
    "\tsma_a_features = [(f[0].replace('home','away'), f[1].replace('home','away')) for f in sma_h_features]\n",
    "\n",
    "\tfor idx, row in tqdm(match_df.iterrows(), total=match_df.shape[0]):\n",
    "\t\tprev_h_matches = get_prev_matches(row['date'], row['home_id'], match_df).tail(window_size)\n",
    "\t\tprev_a_matches = get_prev_matches(row['date'], row['away_id'], match_df).tail(window_size)\n",
    "\t\tlen_prev_h_matches = len(prev_h_matches)\n",
    "\t\tlen_prev_a_matches = len(prev_a_matches)\n",
    "\t\tfor i in range(len(ema_h_features)):\n",
    "\t\t\th_feature = re.findall('home_.*_ema', ema_h_features[i][0])[0].replace('_ema', '')\n",
    "\t\t\ta_feature = h_feature.replace('home', 'away') \n",
    "\n",
    "\t\t\tif not prev_h_matches.empty:\n",
    "\t\t\t\tprev_match = prev_h_matches.iloc[-1:]\n",
    "\t\t\t\tmatch_df.at[idx,sma_h_features[i][0]] = get_prev_team_sum(row['home_id'], h_feature, prev_h_matches)/len_prev_h_matches    \n",
    "\n",
    "\t\t\t\tif len_prev_h_matches < window_size:\n",
    "\t\t\t\t\tmatch_df.at[idx,ema_h_features[i][0]] = match_df.loc[idx,sma_h_features[i][0]] \n",
    "\t\t\t\t\tmatch_df.at[idx,ema_h_features[i][1]] = (match_df.loc[idx,sma_h_features[i][0]] \\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t* len_prev_h_matches + row[h_feature])/(len_prev_h_matches + 1)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tmatch_df.at[idx,ema_h_features[i][0]] = prev_match[ema_h_features[i][1]] \\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tif prev_match['home_id'].values[0] == row['home_id'] \\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\telse prev_match[ema_a_features[i][1]]\n",
    "\n",
    "\t\t\t\t\tmatch_df.at[idx,ema_h_features[i][1]] = ema(row[h_feature],  \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tmatch_df.loc[idx,ema_h_features[i][0]], \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\twindow_size)\n",
    "\t\t\telse:\n",
    "\t\t\t\tmatch_df.at[idx,ema_h_features[i][1]] = row[h_feature]\n",
    "\n",
    "\n",
    "\t\t\tif not prev_a_matches.empty:\n",
    "\t\t\t\tprev_match = prev_a_matches.iloc[-1:]\n",
    "\t\t\t\tmatch_df.at[idx,sma_a_features[i][0]] = get_prev_team_sum(row['away_id'], h_feature, prev_a_matches)/len_prev_a_matches\n",
    "\n",
    "\t\t\t\tif len_prev_a_matches < window_size:\n",
    "\t\t\t\t\tmatch_df.at[idx,ema_a_features[i][0]] = match_df.loc[idx,sma_a_features[i][0]] \n",
    "\t\t\t\t\tmatch_df.at[idx,ema_a_features[i][1]] = (match_df.loc[idx,sma_a_features[i][0]] \\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t* len_prev_a_matches + row[a_feature])/(len_prev_a_matches + 1)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tmatch_df.at[idx,ema_a_features[i][0]] = prev_match[ema_h_features[i][1]] \\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tif prev_match['home_id'].values[0] == row['home_id'] \\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\telse prev_match[ema_a_features[i][1]]\n",
    "\n",
    "\t\t\t\t\tmatch_df.at[idx,ema_a_features[i][1]] = ema(row[a_feature],  \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tmatch_df.loc[idx,ema_a_features[i][0]], \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\twindow_size)\n",
    "\t\t\telse:\n",
    "\t\t\t\tmatch_df.at[idx,ema_a_features[i][1]] = row[a_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a726f7f7-b29e-4bd7-8cbe-6175327e4d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothing = 2\n",
    "window_sizes = [3]\n",
    "hth_window_sizes = [1,2]\n",
    "\n",
    "d = defaultdict(list)\n",
    "\n",
    "for w in tqdm(range(len(hth_window_sizes))):\n",
    "    hth_window_size = hth_window_sizes[w]\n",
    "    ema_h_hth_features = \\\n",
    "        [(f'prev_hth_home_pts_ema{hth_window_size}',       f'post_hth_home_pts_ema{hth_window_size}'),\n",
    "        (f'prev_hth_home_bpm_ema{hth_window_size}',       f'post_hth_home_bpm_ema{hth_window_size}'),\n",
    "        (f'prev_hth_home_fg_ema{hth_window_size}',        f'post_hth_home_fg_ema{hth_window_size}'),\n",
    "        (f'prev_hth_home_fg_pct_ema{hth_window_size}',    f'post_hth_home_fg_pct_ema{hth_window_size}'),\n",
    "        (f'prev_hth_home_3p_ema{hth_window_size}',        f'post_hth_home_3p_ema{hth_window_size}'),\n",
    "        (f'prev_hth_home_3p_pct_ema{hth_window_size}',    f'post_hth_home_3p_pct_ema{hth_window_size}'),\n",
    "        (f'prev_hth_home_ft_ema{hth_window_size}',        f'post_hth_home_ft_ema{hth_window_size}'),\n",
    "        (f'prev_hth_home_ft_pct_ema{hth_window_size}',    f'post_hth_home_ft_pct_ema{hth_window_size}'),\n",
    "        (f'prev_hth_home_orb_ema{hth_window_size}',       f'post_hth_home_orb_ema{hth_window_size}'),\n",
    "        (f'prev_hth_home_orb_pct_ema{hth_window_size}',   f'post_hth_home_orb_pct_ema{hth_window_size}'),\n",
    "        (f'prev_hth_home_drb_ema{hth_window_size}',       f'post_hth_home_drb_ema{hth_window_size}'),\n",
    "        (f'prev_hth_home_drb_pct_ema{hth_window_size}',   f'post_hth_home_drb_pct_ema{hth_window_size}'),\n",
    "        (f'prev_hth_home_trb_ema{hth_window_size}',       f'post_hth_home_trb_ema{hth_window_size}'),\n",
    "        (f'prev_hth_home_trb_pct_ema{hth_window_size}',   f'post_hth_home_trb_pct_ema{hth_window_size}'),\n",
    "        (f'prev_hth_home_tov_ema{hth_window_size}',       f'post_hth_home_tov_ema{hth_window_size}'),\n",
    "        (f'prev_hth_home_tov_pct_ema{hth_window_size}',   f'post_hth_home_tov_pct_ema{hth_window_size}'),\n",
    "        (f'prev_hth_home_ast_ema{hth_window_size}',       f'post_hth_home_ast_ema{hth_window_size}'),\n",
    "        (f'prev_hth_home_ast_pct_ema{hth_window_size}',   f'post_hth_home_ast_pct_ema{hth_window_size}'),\n",
    "        (f'prev_hth_home_stl_ema{hth_window_size}',       f'post_hth_home_stl_ema{hth_window_size}'),\n",
    "        (f'prev_hth_home_stl_pct_ema{hth_window_size}',   f'post_hth_home_stl_pct_ema{hth_window_size}'),\n",
    "        (f'prev_hth_home_blk_ema{hth_window_size}',       f'post_hth_home_blk_ema{hth_window_size}'),\n",
    "        (f'prev_hth_home_blk_pct_ema{hth_window_size}',   f'post_hth_home_blk_pct_ema{hth_window_size}'),\n",
    "        (f'prev_hth_home_drtg_ema{hth_window_size}',      f'post_hth_home_drtg_ema{hth_window_size}'),\n",
    "        (f'prev_hth_home_ortg_ema{hth_window_size}',      f'post_hth_home_ortg_ema{hth_window_size}'),\n",
    "        (f'prev_hth_home_efg_pct_ema{hth_window_size}',   f'post_hth_home_efg_pct_ema{hth_window_size}')]\n",
    "\n",
    "    ema_a_hth_features = [(f[0].replace('home','away'),\\\n",
    "        f[1].replace('home','away')) for f in ema_h_hth_features]\n",
    "    sma_h_hth_features = [(f[0].replace('ema','sma'),\\\n",
    "        f[1].replace('ema','sma')) for f in ema_h_hth_features]\n",
    "    sma_a_hth_features = [(f[0].replace('home','away'),\\\n",
    "        f[1].replace('home','away')) for f in sma_h_hth_features]\n",
    "    for idx, row in tqdm(match_df.iterrows(), total=match_df.shape[0]):\n",
    "        prev_hth_matches = get_prev_matches(row['date'],\\\n",
    "            row['home_id'], match_df, row['away_id']).tail(hth_window_size)\n",
    "        len_prev_hth_matches = len(prev_hth_matches)\n",
    "        for i in range(len(ema_h_hth_features)):\n",
    "            h_feature = re.findall('home_.*_ema',\\\n",
    "                ema_h_hth_features[i][0])[0].replace('_ema', '')\n",
    "            a_feature = h_feature.replace('home', 'away') \n",
    "            if not prev_hth_matches.empty:\n",
    "                prev_match = prev_hth_matches.iloc[-1:]\n",
    "\n",
    "                d[sma_h_hth_features[i][0]].append(get_prev_team_sum(row['home_id'],\\\n",
    "                    h_feature, prev_hth_matches)/len_prev_hth_matches)\n",
    "                d[sma_a_hth_features[i][0]].append(get_prev_team_sum(row['away_id'],\\\n",
    "                     a_feature, prev_hth_matches)/len_prev_hth_matches)    \n",
    "\n",
    "\n",
    "                if len_prev_hth_matches < hth_window_size:\n",
    "                    d[ema_h_hth_features[i][0]].append(d[sma_h_hth_features[i][0]][-1])\n",
    "                    d[ema_h_hth_features[i][1]].append((d[sma_h_hth_features[i][0]][-1] \\\n",
    "                        * len_prev_hth_matches + row[h_feature])/(len_prev_hth_matches + 1))\n",
    "                    d[ema_a_hth_features[i][0]].append(d[sma_a_hth_features[i][0]][-1])\n",
    "                    d[ema_a_hth_features[i][1]].append((d[sma_a_hth_features[i][0]][-1] \\\n",
    "                        * len_prev_hth_matches + row[a_feature])/(len_prev_hth_matches + 1))\n",
    "                else:\n",
    "                    d[ema_h_hth_features[i][0]].append(prev_match[ema_h_hth_features[i][1]] \\\n",
    "                                        if prev_match['home_id'].values[0] == row['home_id'] \\\n",
    "                                        else prev_match[ema_a_hth_features[i][1]])\n",
    "\n",
    "                    d[ema_h_hth_features[i][1]].append(ema(row[h_feature],  \n",
    "                                                d[ema_h_hth_features[i][0]][-1], \n",
    "                                                hth_window_size))\n",
    "\n",
    "                    d[ema_a_hth_features[i][0]].append(prev_match[ema_h_hth_features[i][1]] \\\n",
    "                                                if prev_match['home_id'].values[0] == row['home_id'] \\\n",
    "                                                else prev_match[ema_a_hth_features[i][1]])\n",
    "\n",
    "                    d[ema_a_hth_features[i][1]].append(ema(row[h_feature],  \n",
    "                                                d[ema_a_hth_features[i][0]][-1], \n",
    "                                                hth_window_size))\n",
    "            else:\n",
    "                d[ema_h_hth_features[i][1]].append(row[h_feature])\n",
    "                d[ema_a_hth_features[i][1]].append(row[a_feature])\n",
    "\n",
    "\n",
    "for w in tqdm(range(len(window_sizes))):\n",
    "    window_size = window_sizes[w]\n",
    "\n",
    "    ema_h_features = \\\n",
    "        [(f'prev_home_pts_ema{window_size}',       f'post_home_pts_ema{window_size}'),\n",
    "        (f'prev_home_bpm_ema{window_size}',       f'post_home_bpm_ema{window_size}'),\n",
    "        (f'prev_home_fg_ema{window_size}',        f'post_home_fg_ema{window_size}'),\n",
    "        (f'prev_home_fg_pct_ema{window_size}',    f'post_home_fg_pct_ema{window_size}'),\n",
    "        (f'prev_home_3p_ema{window_size}',        f'post_home_3p_ema{window_size}'),\n",
    "        (f'prev_home_3p_pct_ema{window_size}',    f'post_home_3p_pct_ema{window_size}'),\n",
    "        (f'prev_home_ft_ema{window_size}',        f'post_home_ft_ema{window_size}'),\n",
    "        (f'prev_home_ft_pct_ema{window_size}',    f'post_home_ft_pct_ema{window_size}'),\n",
    "        (f'prev_home_orb_ema{window_size}',       f'post_home_orb_ema{window_size}'),\n",
    "        (f'prev_home_orb_pct_ema{window_size}',   f'post_home_orb_pct_ema{window_size}'),\n",
    "        (f'prev_home_drb_ema{window_size}',       f'post_home_drb_ema{window_size}'),\n",
    "        (f'prev_home_drb_pct_ema{window_size}',   f'post_home_drb_pct_ema{window_size}'),\n",
    "        (f'prev_home_trb_ema{window_size}',       f'post_home_trb_ema{window_size}'),\n",
    "        (f'prev_home_trb_pct_ema{window_size}',   f'post_home_trb_pct_ema{window_size}'),\n",
    "        (f'prev_home_tov_ema{window_size}',       f'post_home_tov_ema{window_size}'),\n",
    "        (f'prev_home_tov_pct_ema{window_size}',   f'post_home_tov_pct_ema{window_size}'),\n",
    "        (f'prev_home_ast_ema{window_size}',       f'post_home_ast_ema{window_size}'),\n",
    "        (f'prev_home_ast_pct_ema{window_size}',   f'post_home_ast_pct_ema{window_size}'),\n",
    "        (f'prev_home_stl_ema{window_size}',       f'post_home_stl_ema{window_size}'),\n",
    "        (f'prev_home_stl_pct_ema{window_size}',   f'post_home_stl_pct_ema{window_size}'),\n",
    "        (f'prev_home_blk_ema{window_size}',       f'post_home_blk_ema{window_size}'),\n",
    "        (f'prev_home_blk_pct_ema{window_size}',   f'post_home_blk_pct_ema{window_size}'),\n",
    "        (f'prev_home_drtg_ema{window_size}',      f'post_home_drtg_ema{window_size}'),\n",
    "        (f'prev_home_ortg_ema{window_size}',      f'post_home_ortg_ema{window_size}'),\n",
    "        (f'prev_home_efg_pct_ema{window_size}',   f'post_home_efg_pct_ema{window_size}')]\n",
    "\n",
    "    ema_a_features = [(f[0].replace('home','away'), \\\n",
    "        f[1].replace('home','away')) for f in ema_h_features]\n",
    "    sma_h_features = [(f[0].replace('ema','sma'), \\\n",
    "        f[1].replace('ema','sma')) for f in ema_h_features]\n",
    "    sma_a_features = [(f[0].replace('home','away'), \\\n",
    "        f[1].replace('home','away')) for f in sma_h_features]\n",
    "\n",
    "    for idx, row in tqdm(match_df.iterrows(), total=match_df.shape[0]):\n",
    "        prev_h_matches = get_prev_matches(row['date'], \\\n",
    "            row['home_id'], match_df).tail(window_size)\n",
    "        prev_a_matches = get_prev_matches(row['date'], \\\n",
    "            row['away_id'], match_df).tail(window_size)\n",
    "        len_prev_h_matches = len(prev_h_matches)\n",
    "        len_prev_a_matches = len(prev_a_matches)\n",
    "        for i in range(len(ema_h_features)):\n",
    "            h_feature = re.findall('home_.*_ema', ema_h_features[i][0])[0].replace('_ema', '')\n",
    "            a_feature = h_feature.replace('home', 'away') \n",
    "\n",
    "            if not prev_h_matches.empty:\n",
    "                prev_match = prev_h_matches.iloc[-1:]\n",
    "                d[sma_h_features[i][0]].append(get_prev_team_sum(row['home_id'], \\\n",
    "                    h_feature, prev_h_matches)/len_prev_h_matches)\n",
    "\n",
    "                if len_prev_h_matches < window_size:\n",
    "                    d[ema_h_features[i][0]].append(d[sma_h_features[i][0]][-1]) \n",
    "                    d[ema_h_features[i][1]].append((d[sma_h_features[i][0][-1]] \\\n",
    "                        * len_prev_h_matches + row[h_feature])/(len_prev_h_matches + 1))\n",
    "                else:\n",
    "                    d[ema_h_features[i][0]].append(prev_match[ema_h_features[i][1]] \\\n",
    "                                        if prev_match['home_id'].values[0] == row['home_id'] \\\n",
    "                                        else prev_match[ema_a_features[i][1]])\n",
    "\n",
    "                    d[ema_h_features[i][1]].append(ema(row[h_feature],  \n",
    "                                        d[ema_h_features[i][0]][-1], \n",
    "                                        window_size))\n",
    "            else:\n",
    "                d[ema_h_features[i][1]].append(row[h_feature])\n",
    "\n",
    "\n",
    "            if not prev_a_matches.empty:\n",
    "                prev_match = prev_a_matches.iloc[-1:]\n",
    "                d[sma_a_features[i][0]].append(get_prev_team_sum(row['away_id'], \\\n",
    "                    h_feature, prev_a_matches)/len_prev_a_matches)\n",
    "\n",
    "                if len_prev_a_matches < window_size:\n",
    "                    d[ema_a_features[i][0]].append(d[sma_a_features[i][0]][-1]) \n",
    "                    d[ema_a_features[i][1]].append((d[sma_a_features[i][0]][-1] \\\n",
    "                        * len_prev_a_matches + row[a_feature])/(len_prev_a_matches + 1))\n",
    "                else:\n",
    "                    d[ema_a_features[i][0]].append(prev_match[ema_h_features[i][1]] \\\n",
    "                                if prev_match['home_id'].values[0] == row['home_id'] \\\n",
    "                                else prev_match[ema_a_features[i][1]])\n",
    "\n",
    "                    d[ema_a_features[i][1]].append(ema(row[a_feature],  \n",
    "                                            d[ema_a_features[i][0]][-1], \n",
    "                                            window_size))\n",
    "            else:\n",
    "                d[ema_a_features[i][1]].append(row[a_feature])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c5f684-9168-447d-a3d1-9b51f7db11cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(match_df.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2693db9-4b71-40ed-8b1f-b0e6a6dfa365",
   "metadata": {},
   "source": [
    "## Team Consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28db3f33-301f-42c5-8421-ed87e1c84d71",
   "metadata": {},
   "source": [
    "Percentage of games the favorited team should have won."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d727d77-0d96-4450-94c4-b237bebbb7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_past_wins_as_favorite(team_id, prev_matches, i):\n",
    "    if len(prev_matches) < i: \n",
    "        return None\n",
    "    prev_matches['res'] =  prev_matches.apply(lambda x:\n",
    "                             1 if (x['home_id'] == team_id and x['favorite'] and x['favorite_won']) or \n",
    "                                      (x['away_id'] == team_id and not x['favorite'] and x['favorite_won'])        \n",
    "                             else 0, axis=1)\n",
    "    return prev_matches['res'].sum()/i    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570ab9bb-d703-4d5c-80a1-135c3a711a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# favorite = 1: home team is favorite.\n",
    "# favorite = 0: away team is favorite\n",
    "match_df['favorite'] = match_df['home_ml'] < match_df['away_ml']\n",
    "match_df['favorite_won'] = match_df.apply(lambda x: (x['favorite'] and x['h_win'] == 1) or\n",
    "                                          (not x['favorite'] and x['h_win'] == 0), axis=1)\n",
    "window_sizes = [2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "for w in tqdm(window_sizes):\n",
    "    match_df[f'past_{w}_home_favorite_wins'] = match_df.apply(lambda x: \n",
    "                                    get_past_wins_as_favorite(x['home_id'], \n",
    "                                        get_prev_matches(x['date'], \n",
    "                                                         x['home_id'],\n",
    "                                                         match_df\n",
    "                                                        ).tail(w),\n",
    "                                                    w), axis=1)\n",
    "    match_df[f'past_{w}_away_favorite_wins'] = match_df.apply(lambda x: \n",
    "                                    get_past_wins_as_favorite(x['away_id'], \n",
    "                                        get_prev_matches(x['date'], \n",
    "                                                         x['away_id'],\n",
    "                                                         match_df\n",
    "                                                        ).tail(w),\n",
    "                                                    w), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a73d7ab-bf20-4d34-bd97-f13ad3f49f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_a = match_df[(match_df['away_id'] == 1) | (match_df['home_id'] == 1)][['home_id', \n",
    "                                                                            'away_id', \n",
    "                                                                            'date', \n",
    "                                                                            'movl', \n",
    "                                                                            'h_win', \n",
    "                                                                            'favorite',\n",
    "                                                                            'favorite_won',\n",
    "                                                                            'past_5_home_favorite_wins',\n",
    "                                                                            'past_5_away_favorite_wins',\n",
    "                                                                           ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7019d15a-adc1-49f3-860e-d83da3f268e9",
   "metadata": {},
   "source": [
    "## Roster Consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2810eb2f-296e-4104-8df5-ce71d3f125e2",
   "metadata": {},
   "source": [
    "Intersection of subsets of rosters over past 10 games"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0f1f1a24-dae8-411c-8360-fa37d79fc703",
   "metadata": {},
   "source": [
    "def get_active_players(match_id, team_id, pp_df):\n",
    "    return  pp_df[(pp_df['match_id'] == match_id) &\n",
    "                      (pp_df['team_id'] == team_id) &\n",
    "                  (pp_df['sp']>0)]\n",
    "\n",
    "def get_complete_roster(prev_matches, team_id, match_df):\n",
    "    return  pp_df[(pp_df['match_id'] == match_id) &\n",
    "                      (pp_df['team_id'] == team_id)]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ace78e98-0c74-417f-9de1-7452f39a7a3e",
   "metadata": {},
   "source": [
    "match_df['home_roster'] = match_df.apply(lambda x: \n",
    "                                get_active_players(x['match_id'],\n",
    "                                            x['home_id'],\n",
    "                                            pp_df)['player_id'].to_list(), axis=1)\n",
    "match_df['away_roster'] = match_df.apply(lambda x: \n",
    "                                get_active_players(x['match_id'],\n",
    "                                            x['away_id'],\n",
    "                                            pp_df)['player_id'].to_list(), axis=1)\n",
    "\n",
    "# get past 10 roster set\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f185d4e4-1dda-4711-ba9c-a7886375ef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df = match_df[match_df['date'] >= datetime(2007,10,30)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe571e7-e0e4-4b94-b42a-897542fff53d",
   "metadata": {},
   "source": [
    "# Save raw stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d85b2ed-d68d-4a5d-a530-ecb08d8cf8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "season_df.to_csv('seasons.csv', header=True, index=False)\n",
    "match_df.to_csv('matches.csv', header=True, index=False)\n",
    "pp_df.to_csv('playerperformances.csv', header=True, index=False)\n",
    "injury_df.to_csv('injuries.csv', header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e41519-574c-4380-b8bd-da3e542debfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df = pd.read_csv('matches.csv')\n",
    "pp_df = pd.read_csv('playerperformances.csv')\n",
    "injury_df = pd.read_csv('injuries.csv')\n",
    "season_df = pd.read_csv('seasons.csv')\n",
    "\n",
    "match_df['date'] = match_df['date'].map(lambda x: datetime.strptime(x , '%Y-%m-%d'))\n",
    "season_df['start_date'] = season_df['start_date'].map(lambda x: datetime.strptime(x , '%Y-%m-%d'))\n",
    "season_df['end_date'] = season_df['end_date'].map(lambda x: datetime.strptime(x , '%Y-%m-%d'))\n",
    "pp_df['date'] = pp_df['date'].map(lambda x: datetime.strptime(x , '%Y-%m-%d'))\n",
    "pp_df['season'] = pp_df['date'].map(get_season)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c514537-3568-4597-a1c8-90d8f79c2eca",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632fef9a-df39-489a-a397-43e1f0165856",
   "metadata": {},
   "source": [
    "Remove all rows where there were not enough games yet to calculate certain statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ed5883-f0f8-4541-9b03-bbc6c467d0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df = match_df[(match_df['past_5_away_pts'].notnull()) &\n",
    "                   (match_df['past_5_home_pts'].notnull())].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25248a2c-8689-4d19-b722-44bad5649604",
   "metadata": {},
   "source": [
    "## Balance Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04f716c-4e29-411d-9f9e-a57c77df8a5d",
   "metadata": {},
   "source": [
    "Get ratio of home_team wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464491bd-71d5-4d58-adaa-e950f47a5f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(match_df[match_df['movl']>0]) / len(match_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d00c206-0d27-4020-8b7a-26c59578f6f8",
   "metadata": {},
   "source": [
    "### Alternate between home win and away win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a5fda7-e045-42de-8b5c-e8715a47e413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make odd rows home_win = 1\n",
    "unchanged_odd_rows = match_df[(match_df.index % 2 != 0) & (match_df['h_win'] == 1)].copy()\n",
    "modified_odd_rows = match_df[(match_df.index % 2 != 0) & (match_df['h_win'] == 0)].copy()\n",
    "\n",
    "# make even rows home_win = 0\n",
    "unchanged_even_rows = match_df[(match_df.index % 2 == 0) & (match_df['h_win'] == 0)].copy()\n",
    "modified_even_rows = match_df[(match_df.index % 2 == 0) & (match_df['h_win'] == 1)].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2903ed-10e2-4bf8-8933-f2379d208653",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "cols = list(modified_odd_rows)\n",
    "for i in range(len(cols)):\n",
    "    if re.findall('away',cols[i]):\n",
    "        cols[i] = cols[i].replace('away', 'home')\n",
    "    elif re.findall('home',cols[i]):\n",
    "        cols[i] = cols[i].replace('home', 'away')\n",
    "modified_odd_rows['movl'] = modified_odd_rows['movl'] * -1\n",
    "modified_odd_rows.set_axis(cols, axis=1, inplace=True)\n",
    "modified_even_rows['movl'] = modified_even_rows['movl'] * -1\n",
    "modified_even_rows.set_axis(cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2142db63-7f5b-4ed4-b80d-318cccf136e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = pd.concat([unchanged_odd_rows, \n",
    "                          modified_odd_rows, \n",
    "                          unchanged_even_rows, \n",
    "                          modified_even_rows], \n",
    "                         ignore_index = True)\n",
    "processed_df = processed_df.sort_values(by='date')\n",
    "processed_df['h_win'] = processed_df['movl'].map(lambda x: 0 if x < 0 else 1)\n",
    "processed_df.rename(columns = {'h_win':'home_win'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac90a186-fb5f-4af1-92d3-05761ee45142",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_pdf = processed_df[['date', 'home_pts' , 'away_pts', 'movl', 'home_win']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db506e7-3187-4db9-816d-45f43f54f9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(processed_df[processed_df['movl']>0]) / len(processed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56056042-3273-4887-8729-b83bac2fa984",
   "metadata": {},
   "source": [
    "## Save Final Dataset into CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ed3d57-e2f6-48a0-8026-29e737f41bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df.rename(columns = {'h_win':'home_win'}, inplace = True)\n",
    "match_df.to_csv('nba_data.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cd60bd-b0ed-40ed-969c-f4988e06c82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df = pd.read_csv('nba_data.csv')\n",
    "\n",
    "match_df.to_csv('nba_data.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12171ebb-3786-45e7-a3a2-9bb166b2da58",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df['home_win']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06865461-6817-44b1-8d29-335e58d4ff12",
   "metadata": {},
   "source": [
    "## Feature Correlation Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a012e0-deda-4314-88d2-f8f6fde4281e",
   "metadata": {},
   "source": [
    "All features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4f50df-08f6-4c31-b80a-7886acc3aa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 4\n",
    "hth_window_size = 3\n",
    "\n",
    "ema_h_features = [(f'prev_home_pts_ema{window_size}',       f'post_home_pts_ema{window_size}'),\n",
    "                  (f'prev_home_bpm_ema{window_size}',       f'post_home_bpm_ema{window_size}'),\n",
    "                  (f'prev_home_fg_ema{window_size}',        f'post_home_fg_ema{window_size}'),\n",
    "                  (f'prev_home_fg_pct_ema{window_size}',    f'post_home_fg_pct_ema{window_size}'),\n",
    "                  (f'prev_home_3p_ema{window_size}',        f'post_home_3p_ema{window_size}'),\n",
    "                  (f'prev_home_3p_pct_ema{window_size}',    f'post_home_3p_pct_ema{window_size}'),\n",
    "                  (f'prev_home_ft_ema{window_size}',        f'post_home_ft_ema{window_size}'),\n",
    "                  (f'prev_home_ft_pct_ema{window_size}',    f'post_home_ft_pct_ema{window_size}'),\n",
    "                  (f'prev_home_orb_ema{window_size}',       f'post_home_orb_ema{window_size}'),\n",
    "                  (f'prev_home_orb_pct_ema{window_size}',   f'post_home_orb_pct_ema{window_size}'),\n",
    "                  (f'prev_home_drb_ema{window_size}',       f'post_home_drb_ema{window_size}'),\n",
    "                  (f'prev_home_drb_pct_ema{window_size}',   f'post_home_drb_pct_ema{window_size}'),\n",
    "                  (f'prev_home_trb_ema{window_size}',       f'post_home_trb_ema{window_size}'),\n",
    "                  (f'prev_home_trb_pct_ema{window_size}',   f'post_home_trb_pct_ema{window_size}'),\n",
    "                  (f'prev_home_tov_ema{window_size}',       f'post_home_tov_ema{window_size}'),\n",
    "                  (f'prev_home_tov_pct_ema{window_size}',   f'post_home_tov_pct_ema{window_size}'),\n",
    "                  (f'prev_home_ast_ema{window_size}',       f'post_home_ast_ema{window_size}'),\n",
    "                  (f'prev_home_ast_pct_ema{window_size}',   f'post_home_ast_pct_ema{window_size}'),\n",
    "                  (f'prev_home_stl_ema{window_size}',       f'post_home_stl_ema{window_size}'),\n",
    "                  (f'prev_home_stl_pct_ema{window_size}',   f'post_home_stl_pct_ema{window_size}'),\n",
    "                  (f'prev_home_blk_ema{window_size}',       f'post_home_blk_ema{window_size}'),\n",
    "                  (f'prev_home_blk_pct_ema{window_size}',   f'post_home_blk_pct_ema{window_size}'),\n",
    "                  (f'prev_home_drtg_ema{window_size}',      f'post_home_drtg_ema{window_size}'),\n",
    "                  (f'prev_home_ortg_ema{window_size}',      f'post_home_ortg_ema{window_size}'),\n",
    "                  (f'prev_home_efg_pct_ema{window_size}',   f'post_home_efg_pct_ema{window_size}')]\n",
    "\n",
    "ema_a_features = [(f[0].replace('home','away'), f[1].replace('home','away')) for f in ema_h_features]\n",
    "sma_h_features = [f[0].replace('ema','sma') for f in ema_h_features]\n",
    "sma_a_features = [f.replace('home','away') for f in sma_h_features]\n",
    "\n",
    "ema_h_hth_features = [(f'prev_hth_home_pts_ema{hth_window_size}',       f'post_hth_home_pts_ema{hth_window_size}'),\n",
    "                      (f'prev_hth_home_bpm_ema{hth_window_size}',       f'post_hth_home_bpm_ema{hth_window_size}'),\n",
    "                      (f'prev_hth_home_fg_ema{hth_window_size}',        f'post_hth_home_fg_ema{hth_window_size}'),\n",
    "                      (f'prev_hth_home_fg_pct_ema{hth_window_size}',    f'post_hth_home_fg_pct_ema{hth_window_size}'),\n",
    "                      (f'prev_hth_home_3p_ema{hth_window_size}',        f'post_hth_home_3p_ema{hth_window_size}'),\n",
    "                      (f'prev_hth_home_3p_pct_ema{hth_window_size}',    f'post_hth_home_3p_pct_ema{hth_window_size}'),\n",
    "                      (f'prev_hth_home_ft_ema{hth_window_size}',        f'post_hth_home_ft_ema{hth_window_size}'),\n",
    "                      (f'prev_hth_home_ft_pct_ema{hth_window_size}',    f'post_hth_home_ft_pct_ema{hth_window_size}'),\n",
    "                      (f'prev_hth_home_orb_ema{hth_window_size}',       f'post_hth_home_orb_ema{hth_window_size}'),\n",
    "                      (f'prev_hth_home_orb_pct_ema{hth_window_size}',   f'post_hth_home_orb_pct_ema{hth_window_size}'),\n",
    "                      (f'prev_hth_home_drb_ema{hth_window_size}',       f'post_hth_home_drb_ema{hth_window_size}'),\n",
    "                      (f'prev_hth_home_drb_pct_ema{hth_window_size}',   f'post_hth_home_drb_pct_ema{hth_window_size}'),\n",
    "                      (f'prev_hth_home_trb_ema{hth_window_size}',       f'post_hth_home_trb_ema{hth_window_size}'),\n",
    "                      (f'prev_hth_home_trb_pct_ema{hth_window_size}',   f'post_hth_home_trb_pct_ema{hth_window_size}'),\n",
    "                      (f'prev_hth_home_tov_ema{hth_window_size}',       f'post_hth_home_tov_ema{hth_window_size}'),\n",
    "                      (f'prev_hth_home_tov_pct_ema{hth_window_size}',   f'post_hth_home_tov_pct_ema{hth_window_size}'),\n",
    "                      (f'prev_hth_home_ast_ema{hth_window_size}',       f'post_hth_home_ast_ema{hth_window_size}'),\n",
    "                      (f'prev_hth_home_ast_pct_ema{hth_window_size}',   f'post_hth_home_ast_pct_ema{hth_window_size}'),\n",
    "                      (f'prev_hth_home_stl_ema{hth_window_size}',       f'post_hth_home_stl_ema{hth_window_size}'),\n",
    "                      (f'prev_hth_home_stl_pct_ema{hth_window_size}',   f'post_hth_home_stl_pct_ema{hth_window_size}'),\n",
    "                      (f'prev_hth_home_blk_ema{hth_window_size}',       f'post_hth_home_blk_ema{hth_window_size}'),\n",
    "                      (f'prev_hth_home_blk_pct_ema{hth_window_size}',   f'post_hth_home_blk_pct_ema{hth_window_size}'),\n",
    "                      (f'prev_hth_home_drtg_ema{hth_window_size}',      f'post_hth_home_drtg_ema{hth_window_size}'),\n",
    "                      (f'prev_hth_home_ortg_ema{hth_window_size}',      f'post_hth_home_ortg_ema{hth_window_size}'),\n",
    "                      (f'prev_hth_home_efg_pct_ema{hth_window_size}',   f'post_hth_home_efg_pct_ema{hth_window_size}')]\n",
    "\n",
    "ema_a_hth_features = [(f[0].replace('home','away'), f[1].replace('home','away')) for f in ema_h_hth_features]\n",
    "sma_h_hth_features = [f[0].replace('ema','sma') for f in ema_h_hth_features]\n",
    "sma_a_hth_features = [f.replace('home','away') for f in sma_h_hth_features]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb65b918-4d61-47a3-bf22-ce1f4619929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "ema_h_features = [x[0] for x in ema_h_features]\n",
    "ema_a_features = [x[0] for x in ema_a_features]\n",
    "\n",
    "ema_h_hth_features = [x[0] for x in ema_h_hth_features]\n",
    "ema_a_hth_features = [x[0] for x in ema_a_hth_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b0f13a-3b86-4b84-8346-2d0b5da2f183",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['prev_home_elo', 'prev_away_elo', \n",
    "            'home_ml', 'away_ml']\n",
    "corr_df = match_df[features]\n",
    "\n",
    "corr = corr_df.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')\n",
    "\n",
    "# 'RdBu_r', 'BrBG_r', & PuOr_r are other good diverging colormaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d2c722-ee7f-4ddb-92c0-a4671e2d7a6d",
   "metadata": {},
   "source": [
    "# Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39cea23-1a37-47df-b417-81aa75b888cd",
   "metadata": {},
   "source": [
    "# Splitting into Training and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36d97fe-8634-4fb6-8d53-b5e38cc7100d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Simple 80/20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d99fa39-a287-44c7-a850-d9c5e04d806c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "match_df = pd.read_csv('nba_data.csv')\n",
    "match_df['home_win'] = match_df['movl'].map(lambda x: 0 if x < 0 else 1)\n",
    "\n",
    "features = ['prev_home_player_elo_avg', 'prev_away_player_elo_avg', \n",
    "            'past_5_home_favorite_wins','past_5_away_favorite_wins',\n",
    "            'home_ml']\n",
    "all_ema_features = features + ema_h_features + ema_a_features + ema_h_hth_features +ema_a_hth_features\n",
    "all_sma_features = features + sma_h_features + sma_a_features + sma_h_hth_features +sma_a_hth_features\n",
    "\n",
    "cutoff = math.floor(len(match_df) * 0.7)\n",
    "train = match_df[match_df.index < cutoff].copy()\n",
    "test = match_df[match_df.index >= cutoff].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b0f3b2-214f-4fb8-8f19-2b476a45b02a",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db801af-93f0-4eb2-8a5b-0265930011dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "import matplotlib.pyplot as pl\n",
    "import xgboost as xgb\n",
    "import sklearn.metrics\n",
    "from matplotlib import pyplot\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "\n",
    "X_train = train[all_sma_features]\n",
    "X_test = test[all_sma_features]\n",
    "\n",
    "# y_train = train['movl']\n",
    "# y_test = test['movl']\n",
    "\n",
    "y_train = train['home_win']\n",
    "y_test = test['home_win']\n",
    "\n",
    "evalset = [(X_train, y_train), (X_test,y_test)]\n",
    "\n",
    "params = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    # Other parameters\n",
    "    'objective':'reg:squarederror',\n",
    "    'random_state': 1\n",
    "}\n",
    "xgb_model = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                           colsample_bytree = 1, \n",
    "                           learning_rate = 0.1,\n",
    "                           max_depth = 5, \n",
    "                           alpha = 70,\n",
    "                           n_estimators = 10,\n",
    "                           gamma = 0.4,\n",
    "                           min_child_weight=3,\n",
    "                           random_state=1,\n",
    "                           subsample=1,\n",
    "                           eta = 0.1,\n",
    "                           tree_method='gpu_hist',\n",
    "                           use_label_encoder=False)\n",
    "\n",
    "xgb_model.fit(X_train,y_train, eval_metric='logloss', eval_set =evalset, verbose=0)\n",
    "\n",
    "\n",
    "# evaluate performance\n",
    "yhat = xgb_model.predict(X_test)\n",
    "score = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.3f' % score)\n",
    "# retrieve performance metrics\n",
    "results = xgb_model.evals_result()\n",
    "# plot learning curves\n",
    "plt.plot(results['validation_0']['logloss'], label='train')\n",
    "plt.plot(results['validation_1']['logloss'], label='test')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a52e933-0b9a-4561-b680-62e04bf56c04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607b9fca-ccd3-40e9-8e16-5b8f5f3b3144",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "xgb.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045c6e71-5be2-4fbd-b2a2-4a3a999aae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xgb.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(f'RMSE: {rmse}')\n",
    "preds = pd.Series(preds, name='xgb_movl')\n",
    "pred_df = pd.concat([y_test.reset_index(drop=True), \n",
    "                preds.reset_index(drop=True),\n",
    "               test['home_ml'].reset_index(drop=True),\n",
    "               test['away_ml'].reset_index(drop=True)], axis=1)\n",
    "pred_df['home_win'] = pred_df['movl'].map(lambda x: 0 if x < 0 else 1)\n",
    "pred_df['xgb_home_win'] = pred_df['xgb_movl'].map(lambda x: 0 if x < 0 else 1)\n",
    "pred_df['correct_pred'] = pred_df.apply(lambda x: \n",
    "    1 if x['home_win'] == x['xgb_home_win'] else 0, axis = 1)\n",
    "acc = pred_df['correct_pred'].sum()/len(df.index)\n",
    "print(f'Accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9078b61a-d1e4-4e2b-86ff-58a9aa1715ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(xgb_model)\n",
    "pl.title(\"xgboost.plot_importance(model)\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0589a0-c1f8-4b51-8ea2-8d46cbb2cc39",
   "metadata": {},
   "source": [
    "## Accuracy of using just ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f01653-d198-4b4e-99c6-cae6d5ca06bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df['ml_pred'] = pred_df.apply(lambda x: \n",
    "    1 if x['home_ml'] < x['away_ml'] else 0, axis = 1)\n",
    "\n",
    "pred_df['ml_correct_pred'] = pred_df.apply(lambda x: \n",
    "    1 if x['home_win'] == x['ml_pred'] else 0, axis = 1)\n",
    "\n",
    "acc = pred_df['ml_correct_pred'].sum()/len(df.index)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16b8def-d425-4098-aae1-a5d768360315",
   "metadata": {},
   "source": [
    "## Tuning XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7f47e5-99ee-4bca-8c5b-8ef372635291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train_index, test_index in tscv.split(X):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#     X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "#     y_train, y_test = y[train_index], y[test_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c438bf31-c680-407f-b78c-139dda0c5199",
   "metadata": {},
   "source": [
    "### TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721b939b-0fd6-4ac5-8451-4bf5cd5ee652",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pylab as pl\n",
    "import xgboost as xgb\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "print(tscv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8be693d-c601-4701-bf1b-22cd81d53a20",
   "metadata": {},
   "source": [
    "### GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91297cf-427d-479d-a553-b0a621ad2607",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tee(object):\n",
    "    def __init__(self, *files):\n",
    "        self.files = files\n",
    "    def write(self, obj):\n",
    "        for f in self.files:\n",
    "            f.write(obj)\n",
    "            f.flush() # If you want the output to be visible immediately\n",
    "    def flush(self) :\n",
    "        for f in self.files:\n",
    "            f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8c9255-fd2c-4058-b163-b943463203af",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# logfile = open('xgb_tuning.txt', 'w')\n",
    "# original_stderr = sys.stderr\n",
    "# original_stdout = sys.stdout\n",
    "\n",
    "# sys.stdout = Tee(sys.stdout, logfile)\n",
    "# sys.stderr = sys.stdout\n",
    "\n",
    "params = {\n",
    "        'min_child_weight':[1, 2, 3, 10],\n",
    "        'alpha':[10,50,100],\n",
    "        'gamma':[0.05,0.1,0.2,0.3,0.4,1],\n",
    "        'lambda':[1,10],\n",
    "        'subsample':[0.6, 0.8, 1.0],\n",
    "        'colsample_bytree':[0.4, 0.6, 0.8, 1.0],\n",
    "        'max_depth':[4,6,10,20],\n",
    "        'n_estimators':[10,50,100,200,300],\n",
    "        'learning_rate':[0.001, 0.01,0.1,0.2, 0.3]\n",
    "        }\n",
    "# grid_search = GridSearchCV(estimator = xgb_model, \n",
    "#                            cv = tscv, \n",
    "#                            scoring = 'neg_root_mean_squared_error',\n",
    "#                            param_grid = params)\n",
    "xgb_model = xgb.XGBClassifier(tree_method = 'gpu_hist', \n",
    "                              gpu_id = 0, \n",
    "                              eval_metric='logloss', \n",
    "                              random_state = 1,\n",
    "                              use_label_encoder=False)\n",
    "X_train = train[all_sma_features]\n",
    "X_test = test[all_sma_features]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = xgb_model, \n",
    "                           cv = tscv, \n",
    "                           scoring = 'accuracy',\n",
    "                           param_grid = params,\n",
    "                           n_jobs = 1,\n",
    "                           verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# sys.stdout = original_stdout\n",
    "# sys.stderr = original_stderr\n",
    "# logfile.close()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046a4595-9610-4969-afdb-c9db98700203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_name = \"xgb_sma_tuned.pkl\"\n",
    "# save\n",
    "pickle.dump(grid_search.best_estimator_, open(file_name, \"wb\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692ec00b-b48b-4f87-beed-c5ae5ae6d1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",grid_search.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",grid_search.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7e75e8-094b-4946-9fa3-1438ba97d1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "grid_search.best_estimator_.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd48195c-0229-47b1-ab14-998bb8f6d580",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'min_child_weight':[1, 2, 3, 5, 7, 15,30],\n",
    "        'alpha':[1,10,30,50,70,100],\n",
    "        'gamma':[0.05, 0.1, 0.25, 0.5, 0.75],\n",
    "        'lambda':[1,10,30,50],\n",
    "        'subsample':[0.6, 0.8, 1.0],\n",
    "        'colsample_bytree':[0.4, 0.6, 0.8, 1.0],\n",
    "        'max_depth':[2,3,5, 7, 9],\n",
    "        'n_estimators':[1,2,3,5,10,20],\n",
    "        'eta':[0.1,0.3,0.5,0.7],\n",
    "        'eval_metric':['logloss'],\n",
    "        'random_state':[1],\n",
    "        }\n",
    "# grid_search = GridSearchCV(estimator = xgb_model, \n",
    "#                            cv = tscv, \n",
    "#                            scoring = 'neg_root_mean_squared_error',\n",
    "#                            param_grid = params)\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False)\n",
    "X_train = train[all_ema_features]\n",
    "X_test = test[all_ema_features]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = xgb_model, \n",
    "                           cv = tscv, \n",
    "                           scoring = 'roc_auc',\n",
    "                           param_grid = params,\n",
    "                           n_jobs = -1,\n",
    "                           verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "import pickle\n",
    "file_name = \"xgb_ema_tuned.pkl\"\n",
    "# save\n",
    "pickle.dump(grid_search.best_estimator_, open(file_name, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da0af7a-9c61-4980-9ee0-82b7a16ce349",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",grid_search.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",grid_search.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4ac098-0c23-4600-8491-aed8a90d6eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "grid_search.best_estimator_.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07f84b8-6b29-4270-b33c-21f497f34ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_preds = grid_search.best_estimator_.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, cv_preds))\n",
    "print(f'RMSE: {rmse}')\n",
    "\n",
    "pred_df['xgbcv_movl'] = cv_preds\n",
    "pred_df['xgbcv_home_win'] = pred_df['xgbcv_movl'].map(lambda x: 0 if x < 0 else 1)\n",
    "pred_df['correct_cv_pred'] = pred_df.apply(lambda x: \n",
    "     1 if x['home_win'] == x['xgbcv_home_win'] else 0, axis = 1)\n",
    "acc = pred_df['correct_cv_pred'].sum()/len(df.index)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d8c0a0-040b-4c8e-9780-01790ab96581",
   "metadata": {},
   "source": [
    "### Save tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6f52f3-135d-4890-a950-8e0454699a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_name = \"xgb_reg.pkl\"\n",
    "# save\n",
    "pickle.dump(grid_search.best_estimator_, open(file_name, \"wb\"))\n",
    "\n",
    "# load\n",
    "xgb_model_loaded = pickle.load(open(file_name, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35a1dec-94a6-4ce1-a661-986dcd43ddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(xgb_model_loaded)\n",
    "pl.title(\"xgboost.plot_importance(model)\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a626d7-acaa-4f20-bdcb-e52ce2c55fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in tscv.split(X_train):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c65bc7-0aab-4550-aed2-7b2732e433fc",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20165ec4-1241-4f12-9825-eede8aa59063",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "lr_train = train.replace([np.inf, -np.inf], np.nan).dropna(subset=all_features, how=\"any\")\n",
    "\n",
    "X_train = lr_train[all_features]\n",
    "X_test = test[all_features]\n",
    "\n",
    "y_train = lr_train['home_win']\n",
    "y_test = test['home_win']\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_test)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#print(X_test.mean(axis=0), X_test.std(axis=0))\n",
    "\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "penalty = ['l2']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01, 0.001]\n",
    "\n",
    "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "\n",
    "\n",
    "logreg=LogisticRegression(random_state=1,max_iter=1000)\n",
    "logreg_cv=GridSearchCV(estimator=logreg,\n",
    "                       param_grid=grid,\n",
    "                       cv = tscv,\n",
    "                       scoring='accuracy',\n",
    "                       error_score=0,\n",
    "                       verbose=1)\n",
    "\n",
    "logreg_cv.fit(X_train, y_train)\n",
    "lr_pred = logreg_cv.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f912f29d-bdfd-43ef-912a-efac168fdeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",logreg_cv.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",logreg_cv.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",logreg_cv.best_params_)\n",
    "print(\"\\n The test accuracy is:\\n\",metrics.accuracy_score(y_test, lr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b05d17-e2aa-4c54-9a78-c0df55835828",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db606769-08c6-458d-8672-ef6ccb817190",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "ridge_train = train.replace([np.inf, -np.inf], np.nan).dropna(subset=all_features, how=\"any\")\n",
    "\n",
    "X_train = ridge_train[features]\n",
    "X_test = test[features]\n",
    "\n",
    "y_train = ridge_train['home_win']\n",
    "y_test = test['home_win']\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_test)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "ridge = RidgeClassifier()\n",
    "alpha = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "# define grid search\n",
    "grid = dict(alpha=alpha)\n",
    "grid_search = GridSearchCV(estimator=ridge, \n",
    "                           param_grid=grid, \n",
    "                           n_jobs=-1, \n",
    "                           cv=tscv, \n",
    "                           scoring='accuracy',\n",
    "                           error_score=0,\n",
    "                           verbose=1)\n",
    "ridge_cv = grid_search.fit(X_train, y_train)\n",
    "ridge_pred = ridge_cv.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731edc3c-76bd-4da7-9daf-673a4090a54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",ridge_cv.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",ridge_cv.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",ridge_cv.best_params_)\n",
    "print(\"\\n The test accuracy is:\\n\", metrics.accuracy_score(y_test, ridge_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bc5b98-12b3-4d7c-b32a-4e5d018d7fff",
   "metadata": {},
   "source": [
    "## Knn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fcbb92-75b6-40f5-acdd-5eecea0f6f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "knn_train = train.replace([np.inf, -np.inf], np.nan).dropna(subset=all_sma_features, how=\"any\")\n",
    "\n",
    "X_train = knn_train[all_sma_features]\n",
    "X_test = test[all_sma_features]\n",
    "\n",
    "y_train = knn_train['home_win']\n",
    "y_test = test['home_win']\n",
    "              \n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_test)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "n_neighbors = [1,5,10,50,100]\n",
    "weights = ['uniform', 'distance']\n",
    "metric = ['euclidean', 'manhattan', 'minkowski']\n",
    "          \n",
    "grid = dict(n_neighbors=n_neighbors,\n",
    "            weights=weights,\n",
    "            metric=metric)\n",
    "          \n",
    "grid_search = GridSearchCV(estimator=knn, \n",
    "                           param_grid=grid, \n",
    "                           n_jobs=-1, \n",
    "                           cv=tscv, \n",
    "                           scoring='accuracy',\n",
    "                           error_score=0)\n",
    "knn_cv = grid_search.fit(X_train, y_train)\n",
    "knn_pred = knn_cv.predict(X_test)\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9797d175-1008-4963-b48a-ce8ecf9e826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",knn_cv.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",knn_cv.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",knn_cv.best_params_)\n",
    "print(\"\\n The test accuracy is:\\n\", metrics.accuracy_score(y_test, knn_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcd2931-7668-4fa7-b4a0-2dac43cda595",
   "metadata": {},
   "source": [
    "## SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382dd119-a069-4482-83e9-ec5e57d57413",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "features = ['prev_home_elo', 'prev_away_elo', \n",
    "            'past_3_hth_home_bpm', 'past_3_hth_away_bpm', \n",
    "            'past_3_hth_home_per', 'past_3_hth_away_per',\n",
    "            'past_3_hth_home_drtg', 'past_3_hth_away_drtg',\n",
    "            'home_ml']\n",
    "\n",
    "\n",
    "svm_train = train.replace([np.inf, -np.inf], np.nan).dropna(subset=features, how=\"any\")\n",
    "\n",
    "X_train = svm_train[features]\n",
    "X_test = test[features]\n",
    "\n",
    "y_train = svm_train['home_win']\n",
    "y_test = test['home_win']\n",
    "\n",
    "\n",
    "kernel = ['poly', 'rbf', 'sigmoid']\n",
    "C = [500, 200, 100, 50, 10, 1.0, 0.1, 0.01]\n",
    "gamma = ['scale']\n",
    "\n",
    "grid = dict(kernel=kernel,\n",
    "            C=C,\n",
    "            gamma=gamma)\n",
    "\n",
    "svm = SVC()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=svm, \n",
    "                           param_grid=grid, \n",
    "                           n_jobs=-1, \n",
    "                           cv=tscv, \n",
    "                           scoring='accuracy',\n",
    "                           error_score=0)\n",
    "svm_cv = grid_search.fit(X_train, y_train)\n",
    "svm_pred = svm_cv.predict(X_test)\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8ec814-5a9d-4706-93c8-a15126b7ff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",svm_cv.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",svm_cv.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",svm_cv.best_params_)\n",
    "print(\"\\n The test accuracy is:\\n\", metrics.accuracy_score(y_test, svm_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808f1a7e-85a7-48b8-9e7a-7ede5117a204",
   "metadata": {},
   "source": [
    "# ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e8e24b-1a5e-41ae-8104-00559197ffcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "# generate a no skill prediction (majority class)\n",
    "ns_probs = [0 for _ in range(len(y_test))]\n",
    "lr_probs = logreg_cv.predict_proba(X_test)\n",
    "xgb_probs = xgb.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "xgb_probs = xgb_probs[:, 1]\n",
    "# calculate scores\n",
    "ns_auc = roc_auc_score(y_test, ns_probs)\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "xgb_auc = roc_auc_score(y_test, xgb_probs)\n",
    "\n",
    "# summarize scores\n",
    "print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "print('XGB: ROC AUC=%.3f' % (xgb_auc))\n",
    "\n",
    "# calculate roc curves\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "xgb_fpr, xgb_tpr, _ = roc_curve(y_test, xgb_probs)\n",
    "\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "pyplot.plot(xgb_fpr, xgb_tpr, marker='.', label='XGB')\n",
    "\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40f77e5-e8db-43a1-859c-c736fefa4ce6",
   "metadata": {},
   "source": [
    "# Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09045f99-923b-4315-9801-9b1c4c33536f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['home_implied'] = test['home_ml'].map(lambda x: 1/x)\n",
    "test['away_implied'] = test['away_ml'].map(lambda x: 1/x)\n",
    "pred_probs = logreg_cv.predict_proba(X_test)\n",
    "pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3871f450-f56a-450d-820e-aee89ba5904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cash = 100\n",
    "i = 0\n",
    "skip_bet = False\n",
    "buffer = 0\n",
    "for idx, row in test.iterrows():\n",
    "    prev_cash = cash\n",
    "    \n",
    "    #bet_amount = min(0.02 * cash, 20000)\n",
    "    bet_amount = 1\n",
    "    cash -= bet_amount\n",
    "    bet_home = 0\n",
    "    if row['home_implied'] < pred_probs[i][1]:\n",
    "        bet_home = 1\n",
    "#     elif row['away_implied'] < pred_probs[i][0] + buffer:\n",
    "#         bet_home = 0\n",
    "#     else:\n",
    "#         skip_bet = True\n",
    "        \n",
    "#     if skip_bet: \n",
    "#         skip_bet = False\n",
    "#     el\n",
    "    if row['home_win'] == 1 and bet_home:\n",
    "        cash += bet_amount * row['home_ml'] \n",
    "    if row['home_win'] == 0 and not bet_home:\n",
    "        cash += bet_amount * row['away_ml'] \n",
    "\n",
    "    i += 1\n",
    "    test.at[idx, 'home_bet'] = bet_home\n",
    "    test.at[idx, 'diff'] = cash - prev_cash\n",
    "    test.at[idx, 'cash'] = cash\n",
    "    test.at[idx, 'bet_amount'] = bet_amount\n",
    "\n",
    "print(cash)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf618ddc-401c-4064-a801-4dc89baa1e25",
   "metadata": {},
   "source": [
    "Bet on underdog if there is an edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d072d9-4ee8-44e8-a2e2-9a1317ce8d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "cash = 100\n",
    "i = 0\n",
    "skip_bet = False\n",
    "buffer = 0\n",
    "for idx, row in test.iterrows():\n",
    "    prev_cash = cash\n",
    "    #bet_amount = min(0.02 * cash, 20000)\n",
    "    bet_amount = 1\n",
    "    if row['home_implied'] < row['away_implied']:\n",
    "        if row['home_implied'] < pred_probs[i][1] + buffer:\n",
    "            bet_home = 1\n",
    "        else:\n",
    "            bet_home = 0\n",
    "    else:\n",
    "        if row['away_implied'] < pred_probs[i][0] + buffer:\n",
    "            bet_home = 0\n",
    "        else:\n",
    "            bet_home = 1\n",
    "    cash -= bet_amount\n",
    "\n",
    "#     elif row['away_implied'] < pred_probs[i][0] + buffer:\n",
    "#         bet_home = 0\n",
    "#     else:\n",
    "#         skip_bet = True\n",
    "        \n",
    "#     if skip_bet: \n",
    "#         skip_bet = False\n",
    "#     el\n",
    "    if row['home_win'] == 1 and bet_home:\n",
    "        cash += bet_amount * row['home_ml'] \n",
    "    if row['home_win'] == 0 and not bet_home:\n",
    "        cash += bet_amount * row['away_ml'] \n",
    "\n",
    "    i += 1\n",
    "    test.at[idx, 'home_bet'] = bet_home\n",
    "    test.at[idx, 'diff'] = cash - prev_cash\n",
    "    test.at[idx, 'cash'] = cash\n",
    "    test.at[idx, 'bet_amount'] = bet_amount\n",
    "\n",
    "print(cash)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a78dc8-4dab-4b40-8486-ae2f19dd1fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cash = 1000\n",
    "i = 0\n",
    "skip_bet = False\n",
    "buffer = 0\n",
    "for idx, row in test.iterrows():\n",
    "    prev_cash = cash\n",
    "    bet_amount = min(0.02 * cash, 20000)\n",
    "    #bet_amount = 1\n",
    "    cash -= bet_amount\n",
    "    bet_home = 0\n",
    "    if  pred_probs[i][0] < pred_probs[i][1] + buffer and row['home_implied'] < pred_probs[i][1]:\n",
    "        bet_home = 1\n",
    "#     elif row['away_implied'] < pred_probs[i][0] + buffer:\n",
    "#         bet_home = 0\n",
    "#     else:\n",
    "#         skip_bet = True\n",
    "        \n",
    "    if skip_bet: \n",
    "        skip_bet = False\n",
    "    elif row['home_win'] == 1 and bet_home:\n",
    "        cash += bet_amount * row['home_ml'] \n",
    "    elif row['home_win'] == 0 and not bet_home:\n",
    "        cash += bet_amount * row['away_ml'] \n",
    "\n",
    "    i += 1\n",
    "    test.at[idx, 'home_bet'] = bet_home\n",
    "    test.at[idx, 'diff'] = cash - prev_cash\n",
    "    test.at[idx, 'cash'] = cash\n",
    "    test.at[idx, 'bet_amount'] = bet_amount\n",
    "\n",
    "print(cash)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274d42ec-a10c-4f2f-a5c6-2fdbb42e086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cash = 100\n",
    "i = 0\n",
    "skip_bet = False\n",
    "buffer = 0\n",
    "for idx, row in test.iterrows():\n",
    "    prev_cash = cash\n",
    "    #bet_amount = max(min(0.05 * cash, 20000),1)\n",
    "    bet_amount = 1\n",
    "    cash -= bet_amount\n",
    "    bet_home = 0\n",
    "    if row['home_implied'] > row['away_implied']:\n",
    "        bet_home = 1\n",
    "#     elif row['away_implied'] < pred_probs[i][0] + buffer:\n",
    "#         bet_home = 0\n",
    "#     else:\n",
    "#         skip_bet = True\n",
    "        \n",
    "    if skip_bet: \n",
    "        skip_bet = False\n",
    "    elif row['home_win'] == 1 and bet_home:\n",
    "        cash += bet_amount * row['home_ml'] \n",
    "    elif row['home_win'] == 0 and not bet_home:\n",
    "        cash += bet_amount * row['away_ml'] \n",
    "\n",
    "    i += 1\n",
    "    test.at[idx, 'home_bet'] = bet_home\n",
    "    test.at[idx, 'diff'] = cash - prev_cash\n",
    "    test.at[idx, 'cash'] = cash\n",
    "    test.at[idx, 'bet_amount'] = bet_amount\n",
    "\n",
    "print(cash)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88458be-155d-4159-a94a-6e2b0f4cfa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from bokeh.resources import INLINE\n",
    "import bokeh.io\n",
    "from bokeh import *\n",
    "bokeh.io.output_notebook(INLINE)\n",
    "\n",
    "def plot_pnl(df):\n",
    "#     output_notebook()\n",
    "#     plot = figure(title=\"Profit and Loss\", x_axis_label=\"Date\", y_axis_label=\"Account Balance\", \n",
    "#                   x_axis_type = 'datetime', plot_width=800, plot_height=500)\n",
    "\n",
    "#     y = df['cash'].tolist()\n",
    "#     x = df['date'].tolist()\n",
    "\n",
    "#     plot.circle(x, y, legend_label='Cash',  line_color = 'blue', line_width = 1)\n",
    "\n",
    "#     handle = show(plot, notebook_handle=True)\n",
    "\n",
    "#     # Update the plot title in the earlier cell\n",
    "#     push_notebook(handle=handle)\n",
    "\n",
    "    fig = px.scatter(x =df['date'], y=df[\"cash\"], title='Account Balance')\n",
    "    fig.show()\n",
    "\n",
    "plot_pnl(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c854de-d44c-4c64-aca1-a5c317bbb287",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['home_pred'] = [i[1] for i in pred_probs]\n",
    "test['won_bet'] = test['diff'].apply(lambda x: 1 if x > 0 else 0)\n",
    "check = test[['date', 'home_implied', 'home_pred','away_implied', 'home_bet', 'cash', 'diff','bet_amount', \n",
    "               'home_ml', 'away_ml', 'home_win' ]].copy()\n",
    "print(f'''bets won: {test['won_bet'].sum()} / {len(test)} = {test['won_bet'].sum()/len(test)}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe35644-24d8-4cc1-884f-92a20cdeb1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "biggestwins = test[test['diff']>2]['diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d5657c-1354-4b0e-b9d6-7a684dfbb82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "underdogs = check[( ((check['home_implied'] < check['away_implied']) & (check['home_bet']==1))\n",
    "                   | ((check['home_implied'] > check['away_implied']) & (check['home_bet']==0)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ce017f-d61f-4842-a92a-ef21e5771881",
   "metadata": {},
   "outputs": [],
   "source": [
    "check['diff'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331d3516-e5cd-4221-884e-3379a3f8e499",
   "metadata": {},
   "outputs": [],
   "source": [
    "favorites = test[(test['diff']<0.3) & (test['diff']>0)]['diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c22d839-e7e8-4f5d-94eb-27a0a37d8ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "favorites.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eabe875-f8c0-4eb0-b89e-3fdb00bc4ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "biggestwins.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9435a72-876e-4c4e-9043-3c865fd2af64",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[y_train == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7186aae2-d002-4e64-b334-2e21f7a1983c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(y_train[y_train == 1]) / len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcdd01e-fdc5-4fa0-bdcc-3970e9702615",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false,
  "vscode": {
   "interpreter": {
    "hash": "36a91b42b1608edd3a501cca1319e7e6fbd9b95959ab9f2e8b0d55c03075a702"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
